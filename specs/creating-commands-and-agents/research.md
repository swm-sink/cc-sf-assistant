# Creating Commands & Agents Skills - Research

**Date:** 2025-11-09
**Status:** Research Phase Complete
**Scope:** Deep exploration of patterns for meta-skills that generate slash commands and subagents

---

## Executive Summary

**Objective:** Create two meta-skills (`creating-commands` and `creating-agents`) that follow the proven pattern of `creating-skills`.

**Key Findings:**
1. **Validated Templates:** Multi-agent analysis recommends **6 command templates + 3 agent templates** (9 total, validated against 116 external agents + 12-factor principles)
2. **External Validation:** 116 agents in awesome-claude-code-subagents provide production-tested patterns
3. **Architecture Model:** Follow creating-skills pattern (templates + validators + orchestrator + guides)
4. **Tool Patterns:** Commands allow full tools, agents use 3 distinct tool tiers (read-only, read+web, full)
5. **CSO Not Needed:** Commands/agents use explicit invocation (`/command`, `@agent`), not auto-invocation
6. **Critical Finding:** Orchestration is a COMMAND responsibility, not agent capability (commands coordinate agents)

**Deliverables Needed:**
- `.claude/skills/creating-commands/` - Command generator skill (6 templates)
- `.claude/skills/creating-agents/` - Agent generator skill (3 templates)
- Each with: SKILL.md, templates/, scripts/, references/

**Note:** See `research-validation-addendum.md` for detailed 50+ source validation analysis.

---

## Part 1: Pattern Analysis from creating-skills

### 1.1 Proven Architecture

**Source:** `/home/user/cc-sf-assistant/.claude/skills/creating-skills/`

**Directory Structure:**
```
creating-skills/
‚îú‚îÄ‚îÄ SKILL.md                           # Main skill definition (314 lines)
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îú‚îÄ‚îÄ technique-template.md      # 246 lines, 6 sections
‚îÇ       ‚îú‚îÄ‚îÄ pattern-template.md        # 260 lines, 7 sections
‚îÇ       ‚îú‚îÄ‚îÄ discipline-template.md     # 525 lines, 12 sections
‚îÇ       ‚îî‚îÄ‚îÄ reference-template.md      # 220 lines, 5 sections
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_skill.py              # Orchestrator (382 lines)
‚îÇ   ‚îú‚îÄ‚îÄ validate_yaml.py               # YAML frontmatter (147 lines)
‚îÇ   ‚îú‚îÄ‚îÄ validate_naming.py             # Active voice check (184 lines)
‚îÇ   ‚îú‚îÄ‚îÄ validate_structure.py          # Section count (294 lines)
‚îÇ   ‚îú‚îÄ‚îÄ validate_cso.py                # CSO score (205 lines)
‚îÇ   ‚îî‚îÄ‚îÄ validate_rationalization.py    # Discipline bulletproofing (302 lines)
‚îî‚îÄ‚îÄ references/
    ‚îú‚îÄ‚îÄ cso-guide.md                   # CSO optimization (484 lines)
    ‚îú‚îÄ‚îÄ rationalization-proofing.md    # Discipline techniques (712 lines)
    ‚îî‚îÄ‚îÄ testing-protocol.md            # TDD for skills (350 lines est)
```

**Key Insights:**
- **4 templates** cover skill type spectrum (technique ‚Üí pattern ‚Üí discipline ‚Üí reference)
- **6 validators** ensure quality (5 specific + 1 orchestrator)
- **3 guides** provide progressive disclosure
- **Atomic operations:** Temp dir ‚Üí validate ‚Üí commit or rollback

### 1.2 Template Placeholder Pattern

**Source:** `.claude/skills/creating-skills/assets/templates/technique-template.md`

**Placeholder Format:**
```markdown
---
name: {{SKILL_NAME}}
description: {{CSO_OPTIMIZED_DESCRIPTION}}
---

# {{SKILL_TITLE}}

## Overview

**Purpose:** {{ONE_SENTENCE_PURPOSE}}

**What this technique does:**
- {{BENEFIT_1}}
- {{BENEFIT_2}}
- {{BENEFIT_3}}
```

**Benefits:**
- Clear indication of what needs customization (`{{VARIABLE}}`)
- F-string compatible (Python: `template.format(**replacements)`)
- Easy to validate (search for remaining `{{` after generation)
- Self-documenting (placeholder names explain purpose)

### 1.3 Validation Strategy

**5-Validator Pattern:**

| Validator | Purpose | Exit Codes | Key Checks |
|-----------|---------|------------|------------|
| `validate_yaml.py` | YAML frontmatter syntax | 0=pass, 1=error, 2=warning | Required fields, kebab-case name, description length |
| `validate_naming.py` | Active voice convention | 0=pass, 1=error | Verb-first pattern (`creating-X` not `X-creator`) |
| `validate_structure.py` | Section completeness | 0=pass, 1=error, 2=warning | Required sections by type (6 for technique, 12 for discipline) |
| `validate_cso.py` | Auto-invocation score | 0=pass, 1=error, 2=warning | CSO ‚â•0.7 (trigger phrases, symptom keywords) |
| `validate_rationalization.py` | Discipline proofing | 0=pass, 1=error | Iron Law, negations, table, red flags |

**Orchestrator Pattern:** `generate_skill.py`
1. Interactive prompts (skill name, type, title, description)
2. Select template based on type
3. Generate in temp directory with placeholder replacement
4. Run all validators sequentially
5. If all pass (exit code 0): move to `.claude/skills/{name}/SKILL.md`
6. If any fail (exit code 1): show errors, rollback temp dir
7. Warnings (exit code 2): show but allow commit

---

## Part 2: Command Structure Analysis

### 2.1 Official Requirements

**Source:** `docs.claude.com/en/docs/claude-code/slash-commands` (via research.md)

**YAML Frontmatter Fields:**

| Field | Required | Type | Purpose | Example |
|-------|----------|------|---------|---------|
| `description` | YES | string (‚â§1024 chars) | Shown in /help menu | "Budget vs actual variance analysis with human-in-loop checkpoints" |
| `model` | No | string | Force specific model | `sonnet`, `opus`, `haiku`, or model ID |
| `allowed-tools` | No | array | Restrict tool access | `[Read, Write, Edit, Bash, Glob, Grep]` |
| `argument-hint` | No | string | Hint for args | `<budget-file> <actual-file> [output-file]` |
| `disable-model-invocation` | No | boolean | Prevent auto-invoke | `false` (default) |

**Naming Convention:**
- File: `kebab-case.md` (e.g., `variance-analysis.md`)
- Invocation: `/environment:command-name` (e.g., `/prod:variance-analysis`)
- Environment: `dev/`, `prod/`, `shared/`

### 2.2 Content Structure Patterns

**Pattern A: RPIV (Research ‚Üí Plan ‚Üí Implement ‚Üí Verify)**

**Source:** `.claude/commands/prod/variance-analysis.md` (184 lines)

**Structure:**
```markdown
---
description: Brief description
---

# Command Title

**Usage:** /command <arg1> <arg2> [arg3]
**Purpose:** 1-2 sentence explanation

---

## Workflow (Human-in-Loop)

### STEP 1: RESEARCH Phase
[Investigation steps without implementation]
**CHECKPOINT 1:** Present research findings. Wait for approval.

### STEP 2: PLAN Phase
[Specification creation without implementation]
**CHECKPOINT 2:** Present plan. Wait for approval.

### STEP 3: IMPLEMENT Phase
[Task-by-task execution with progress tracking]

| Task | Status | Notes |
|------|--------|-------|
| Task 1 | Pending | Details |
| Task 2 | Pending | Details |

**CHECKPOINT 3:** Review after major phases.

### STEP 4: VERIFY Phase
[Independent validation]
**CHECKPOINT 4:** Final approval before delivery.

---

## Success Criteria
- [ ] Criterion 1
- [ ] Criterion 2

## Example Invocation
/command file1.xlsx file2.xlsx output.xlsx

## Anti-Patterns
‚ùå Don't do this
‚úÖ Do this instead
```

**Characteristics:**
- 4 human checkpoints (after Research, Plan, mid-Implement, Verify)
- Progress table for implementation tracking
- Success criteria as checklist
- Example invocation with real args
- Anti-patterns section

**Pattern B: Validation Checks**

**Source:** `.claude/commands/shared/sync-docs.md` (269 lines)

**Structure:**
```markdown
---
description: Validate documentation consistency
model: sonnet
---

# Command Title

**Purpose:** What gets validated

---

## Validation Checks

### Check 1: [Name]
**What to verify:** Description
**Expected result:** Success criteria
**Action steps:**
1. Read file X
2. Compare with Y
3. Report status

### Check 2: [Name]
...

---

## Validation Report Format

**Output Structure:**
- ‚úÖ PASS: Description
- ‚ö†Ô∏è WARNING: Description (acceptable)
- ‚ùå ERROR: Description (critical)

---

## Usage Example
/command
Expected output: [sample]
```

**Characteristics:**
- Numbered validation checks (10 in sync-docs)
- No human checkpoints (single execution)
- Structured report format (‚úÖ‚ö†Ô∏è‚ùå)
- Read-only operations
- Clear distinction: critical errors vs acceptable warnings

**Pattern C: Batch Processing**

**Source:** Multi-agent analysis recommendation (not yet implemented)

**Expected Structure:**
```markdown
---
description: Process multiple files with progress tracking
---

# Batch Processing Command

**Usage:** /command <input-dir> <output-dir> [pattern]

---

## Workflow

### Phase 1: Discovery
1. Scan input directory for files matching pattern
2. Count files, estimate processing time
3. Present file list for approval

**CHECKPOINT 1:** Approve file list before processing.

### Phase 2: Processing Loop
For each file:
1. Load and validate
2. Apply transformation
3. Handle errors gracefully (log, continue)
4. Update progress

**Progress Tracking:**
| File | Status | Result | Error |
|------|--------|--------|-------|
| file1.xlsx | Complete | ‚úÖ | - |
| file2.xlsx | In Progress | - | - |
| file3.xlsx | Pending | - | - |

### Phase 3: Summary Report
- Files processed: X/Y
- Successes: X
- Failures: Y (with details)
- Output location: path

---

## Error Handling
- Per-file errors don't stop batch
- Log errors to error_log.txt
- Include failed files in summary
```

**Characteristics:**
- Loop over multiple files
- Per-file error handling (don't stop batch)
- Progress tracking table
- Summary report with counts
- Graceful degradation

### 2.3 Validated Template Recommendations

**Source:** Multi-agent analysis + External pattern research (116 agents, 12-factor principles)

**Expanded Recommendations (6 templates):**

| Template | Score | Use When | Lines | Sections | Unique Features |
|----------|-------|----------|-------|----------|-----------------|
| **COMMAND_RPIV_TEMPLATE.md** | 9.8/10 | Complex workflows (variance, consolidation, audits) | ~250 | 8 | 4 checkpoints, research-first, human-in-loop |
| **COMMAND_VALIDATION_TEMPLATE.md** | 8.6/10 | Systematic checks (docs, config, data quality) | ~200 | 6 | No checkpoints, ‚úÖ‚ö†Ô∏è‚ùå reporting, read-only |
| **COMMAND_BATCH_PROCESSING_TEMPLATE.md** | 8.4/10 | Multiple files/departments/accounts | ~230 | 7 | Per-item errors, progress tracking, summary |
| **COMMAND_DATA_TRANSFORMATION_TEMPLATE.md** | 7.8/10 | ETL pipelines, data migration, format conversion | ~220 | 7 | Load ‚Üí Transform ‚Üí Validate ‚Üí Output, data quality gates |
| **COMMAND_ORCHESTRATION_TEMPLATE.md** | 7.5/10 | Multi-agent coordination, workflow dependencies | ~240 | 8 | Dependency graph, state management, agent coordination |
| **COMMAND_REPORTING_TEMPLATE.md** | 7.2/10 | Analytics, dashboards, executive summaries | ~210 | 7 | Aggregate ‚Üí Analyze ‚Üí Format ‚Üí Distribute, multi-format output |

**Rationale for Expansion:**
- **Data Transformation:** Distinct from RPIV (no research phase, focus on data pipeline quality)
- **Orchestration:** Manages multi-agent workflows with dependency tracking (workflow-orchestrator pattern)
- **Reporting:** Unique aggregation and formatting logic, multiple distribution channels

---

## Part 3: Agent Structure Analysis

### 3.1 Official Requirements

**Source:** Project code-reviewer.md + external awesome-claude-code-subagents

**YAML Frontmatter Fields:**

| Field | Required | Type | Purpose | Example |
|-------|----------|------|---------|---------|
| `name` | YES | string | Agent identifier | `code-reviewer` |
| `description` | YES | string (100-150 chars) | When to invoke | "Expert code reviewer specializing in financial calculations" |
| `tools` | No | array | Tool restrictions | `[Read, Grep, Glob]` |
| `model` | No | string | Force specific model | `sonnet`, `opus`, `haiku` |

**Naming Convention:**
- File: `kebab-case.md` (e.g., `code-reviewer.md`)
- Invocation: `@agent-name` (e.g., `@code-reviewer`)
- Location: `.claude/agents/` (global, no environment split)

### 3.2 Tool Permission Tiers

**Source:** Research analysis + external patterns

| Agent Type | Tools | Purpose | Examples |
|------------|-------|---------|----------|
| **Reviewer** | `Read, Grep, Glob` | Read-only verification | code-reviewer, financial-validator |
| **Researcher** | `Read, Grep, Glob, WebFetch, WebSearch` | Investigation + web | codebase-explorer, documentation-researcher |
| **Domain Specialist** | `Read, Write, Edit, Bash, Glob, Grep` | Constrained expertise | fintech-engineer, python-pro, kubernetes-specialist |

**Key Insight:** Agents have FEWER tools than commands (constraint by type, not per-command basis)

### 3.3 Content Structure Pattern

**Source:** Project code-reviewer.md (255 lines) + external fintech-engineer.md (286 lines)

**Standard Structure:**
```markdown
---
name: agent-name
description: Brief description
tools: Read, Grep, Glob
---

# Role Statement

You are a [seniority] [role] with expertise in [domain]. Your focus spans [areas] with emphasis on [priorities].

---

## When Invoked

1. Query context manager for [requirements]
2. Review [existing state]
3. Analyze [specific aspects]
4. [Action: implement/provide feedback/deliver]

---

## Checklist (Domain-Specific)

- [ ] Criterion 1 verified
- [ ] Criterion 2 achieved
- [ ] Criterion 3 maintained
- [ ] Criterion 4 certified

---

## Domain Area 1
- Sub-item 1
- Sub-item 2
- Sub-item 3

## Domain Area 2
[8-12 bulleted items per area]

## Domain Area 3
[Comprehensive coverage of domain]

---

## Communication Protocol (Optional)

### Context Query Format (JSON)
{
  "requirement": "...",
  "constraints": "..."
}

---

## Workflow Phases (Optional)

### Phase 1: [Name]
- Step 1
- Step 2

### Phase 2: [Name]
- Step 1
- Step 2

### Phase 3: [Name]
- Step 1
- Step 2

---

## Output Format (Critical for Reviewers)

### CRITICAL ISSUES (Must Fix)
- Issue 1: [File:line] - Description - Impact - Fix

### WARNINGS (Should Fix)
- Warning 1: ...

### SUGGESTIONS (Nice to Have)
- Suggestion 1: ...

### VERIFICATION RESULTS
- [ ] Check 1: PASS/FAIL
- [ ] Check 2: PASS/FAIL

### RECOMMENDATION
**APPROVE / REJECT / NEEDS REVISION**
**Rationale:** [Explain decision]

---

## Integration Notes (Optional)

Work with:
- @related-agent-1 on [task]
- @related-agent-2 on [task]

---

## Anti-Patterns (Optional)

‚ùå Bad practice 1
‚ùå Bad practice 2
‚úÖ Good practice 1
‚úÖ Good practice 2
```

**Section Counts by Agent Type:**

**IMPORTANT:** All external agents use **6 major sections** with subsections for workflow phases.

| Agent Type | Major Sections | Length | Depth |
|------------|----------------|--------|-------|
| **Reviewer** | 6 | 275-285 lines | Deep checklists (8 items), read-only verification |
| **Domain Specialist** | 6 | 275-285 lines | Comprehensive domain coverage (8-15 areas) |
| **Researcher** | 6 | 275-285 lines | Investigation structure, web research tools |

**Standard 6-Section Structure:**
1. Role Statement (1-2 paragraphs)
2. Communication Protocol (JSON query format)
3. Checklist (8 items)
4. Development Workflow (3 phases as subsections: Analysis, Implementation, Excellence)
5. Integration Notes (optional)
6. Anti-Patterns (optional)

### 3.4 Validated Template Recommendations

**Source:** Multi-agent analysis + External validation (116 production agents + 12-factor-agents principles)

**CRITICAL UPDATE:** Validated against 50+ sources. Reduced from 6 templates to **3 templates** based on evidence.
See `research-validation-addendum.md` for detailed analysis.

**Final Recommendations (3 templates):**

| Template | Score | Use When | Lines | Tool Tier | Pattern Frequency |
|----------|-------|----------|-------|-----------|-------------------|
| **AGENT_DOMAIN_SPECIALIST_TEMPLATE.md** | 9.5/10 ‚Üë | Financial expert, Python expert, domain knowledge, data analysis, CLI generation | ~280 | Full access | **PRIMARY** - 100+ agents (86%) |
| **AGENT_RESEARCHER_TEMPLATE.md** | 8.6/10 ‚Üë | Codebase exploration, web research, competitive intelligence | ~280 | Read + Web | 6 agents (5%) - DISTINCT web tools |
| **AGENT_REVIEWER_TEMPLATE.md** | 7.8/10 ‚Üì | Code review, security audit, compliance verification | ~280 | Read-only | 4-6 agents (3-5%) - DISTINCT read-only |

**Removed Templates (Anti-Patterns/Redundancies):**
- ‚ùå **AGENT_ORCHESTRATOR** (anti-pattern): Commands coordinate agents, not agents coordinate agents (context isolation violation)
- ‚ùå **AGENT_ANALYZER** (redundant): Same tools/structure as DOMAIN_SPECIALIST; data-analyst IS a domain specialist
- ‚ùå **AGENT_GENERATOR** (redundant): Same tools/structure as DOMAIN_SPECIALIST; cli-developer IS a domain specialist

**Key Architectural Principle:**
- **Commands = Orchestrators** (variance-analysis.md invokes @code-reviewer at checkpoints)
- **Agents = Workers** (domain specialists, researchers, reviewers - single responsibility)
- **Agents NEVER coordinate other agents** (context isolation by design per code-reviewer.md:254)

**Tool Tier Validation:**
- **3 distinct tiers:** Read-only (reviewers), Read+Web (researchers), Full access (specialists)
- **86% of agents** use Domain Specialist pattern (primary template)
- **All agent types use 6 major sections** (not 7-12 as initially proposed)

---

## Part 4: External Validation

### 4.1 awesome-claude-code-subagents Analysis

**Source:** `/home/user/cc-sf-assistant/external/awesome-claude-code-subagents/`

**Statistics:**
- **Total agents:** 116 across 10 categories
- **Average length:** 285 lines (range: 200-315)
- **Most common type:** Domain Specialist (86% of agents)

**Category Distribution:**

| Category | Count | Example Agents |
|----------|-------|----------------|
| Core Development | 11 | api-designer, backend-developer, fullstack-developer |
| Language Specialists | 22 | python-pro, typescript-pro, rust-engineer, golang-pro |
| Infrastructure | 12 | cloud-architect, devops-engineer, kubernetes-specialist |
| Quality & Security | 12 | code-reviewer, security-auditor, penetration-tester |
| Data & AI | 12 | ml-engineer, data-scientist, llm-architect |
| Developer Experience | 9 | cli-developer, documentation-engineer, dx-optimizer |
| Specialized Domains | 18 | **fintech-engineer**, **quant-analyst**, game-developer |
| Business/Product | 7 | product-manager, ux-researcher |
| Meta-Orchestration | 8 | workflow-orchestrator, task-distributor |
| Research/Analysis | 8 | competitive-analyst, trend-analyst |

**Key Patterns Observed:**

1. **Consistent Structure (100% of agents):**
   - YAML frontmatter with name, description, tools
   - Role statement (1-2 paragraphs)
   - "When invoked" section (4 steps)
   - Checklist (8 items)
   - 8-15 domain areas (8-12 bullet points each)
   - Communication protocol (JSON query format)
   - Workflow phases (3 phases)

2. **Tool Usage:**
   - 92% use full tools: `Read, Write, Edit, Bash, Glob, Grep`
   - 8% use read-only: `Read, Grep, Glob` (reviewers, auditors)
   - None use partial tool sets (it's all or read-only)

3. **Domain Specialist Dominance:**
   - 86% are domain specialists (not reviewers)
   - Constrained expertise in specific technology/domain
   - Comprehensive checklists (8+ items)
   - Deep domain coverage (8-15 areas)

4. **Financial Domain Examples:**
   - `fintech-engineer.md`: Payment systems, regulatory compliance, fraud detection
   - `quant-analyst.md`: Statistical models, risk analysis, algorithmic trading
   - `risk-manager.md`: Risk assessment, mitigation strategies

### 4.2 12-factor-agents Principles

**Source:** `/home/user/cc-sf-assistant/external/12-factor-agents/README.md`

**Relevant Factors for Creating-Commands/Agents:**

| Factor | Principle | Application |
|--------|-----------|-------------|
| 1. Natural Language to Tool Calls | LLMs translate intent ‚Üí tool use | Commands/agents define available tools |
| 2. Own Your Prompts | Explicit prompt control | SKILL.md is the prompt for command/agent |
| 3. Own Your Context Window | Explicit context building | Commands use progressive disclosure |
| 7. Contact Humans with Tools | Human-in-loop | Commands use checkpoints, agents deliver to human |
| 8. Own Your Control Flow | Deterministic workflows | RPIV workflow in commands |
| 10. Small, Focused Agents | Single responsibility | Each agent has constrained expertise |

**Key Insight:** Commands and agents ARE deterministic prompts, not agentic loops. They guide Claude's behavior through structured instructions.

---

## Part 5: Comparison - Skills vs Commands vs Agents

### 5.1 Invocation & Discovery

| Aspect | Skills | Commands | Agents |
|--------|--------|----------|--------|
| **Invocation** | Auto (CSO-triggered) | Manual (`/env:name`) | Manual (`@name`) |
| **Discovery** | CSO-optimized description | Description in /help menu | Description in agent list |
| **Arguments** | No (context-driven) | Yes ($1, $2, $3) | No (conversation-driven) |
| **Environment** | Yes (dev/prod/shared skills) | Yes (dev/prod/shared dirs) | No (global agents) |

### 5.2 Structure & Content

| Aspect | Skills | Commands | Agents |
|--------|--------|----------|--------|
| **YAML Fields** | name, description | description, model, tools, args | name, description, tools, model |
| **CSO Required** | YES (‚â•0.7 score) | NO (explicit invocation) | NO (explicit invocation) |
| **Sections** | 6-12 (by type) | 6-8 (by pattern) | 6-15 (by type) |
| **Length** | <200 lines main | 180-270 lines | 200-315 lines |
| **Progressive Disclosure** | references/ subdirs | Inline or link to docs | Inline comprehensive |
| **Validation** | 5 validators | 3-4 validators (TBD) | 3-4 validators (TBD) |

### 5.3 Tools & Permissions

| Aspect | Skills | Commands | Agents |
|--------|--------|----------|--------|
| **Tool Control** | N/A (skills guide) | Optional restrict via `allowed-tools` | Recommended restrict via `tools` |
| **Common Patterns** | Instructional | Full access (Read, Write, Edit, Bash, Glob, Grep) | Type-based (read-only, read+web, full) |
| **Security Model** | Trust (instructions) | Optional constraint | Strong constraint by type |

---

## Part 6: Proposed Architecture

### 6.1 creating-commands Skill

**Directory Structure:**
```
.claude/skills/creating-commands/
‚îú‚îÄ‚îÄ SKILL.md                                    # Main skill (target: <200 lines)
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îú‚îÄ‚îÄ COMMAND_RPIV_TEMPLATE.md            # ~250 lines, 8 sections
‚îÇ       ‚îú‚îÄ‚îÄ COMMAND_VALIDATION_TEMPLATE.md      # ~200 lines, 6 sections
‚îÇ       ‚îú‚îÄ‚îÄ COMMAND_BATCH_PROCESSING_TEMPLATE.md # ~230 lines, 7 sections
‚îÇ       ‚îú‚îÄ‚îÄ COMMAND_DATA_TRANSFORMATION_TEMPLATE.md # ~220 lines, 7 sections
‚îÇ       ‚îú‚îÄ‚îÄ COMMAND_ORCHESTRATION_TEMPLATE.md   # ~240 lines, 8 sections
‚îÇ       ‚îî‚îÄ‚îÄ COMMAND_REPORTING_TEMPLATE.md       # ~210 lines, 7 sections
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_command.py                     # Orchestrator
‚îÇ   ‚îú‚îÄ‚îÄ validate_command_yaml.py                # YAML frontmatter
‚îÇ   ‚îú‚îÄ‚îÄ validate_command_naming.py              # Kebab-case, env prefix
‚îÇ   ‚îú‚îÄ‚îÄ validate_command_structure.py           # Required sections (6 templates)
‚îÇ   ‚îî‚îÄ‚îÄ validate_command_usage.py               # Usage line syntax
‚îî‚îÄ‚îÄ references/
    ‚îú‚îÄ‚îÄ rpiv-workflow-guide.md                  # Deep dive on RPIV pattern
    ‚îú‚îÄ‚îÄ validation-patterns.md                  # Systematic check patterns
    ‚îú‚îÄ‚îÄ batch-processing-guide.md               # Error handling, progress tracking
    ‚îú‚îÄ‚îÄ data-transformation-guide.md            # ETL pipelines, data quality gates
    ‚îú‚îÄ‚îÄ orchestration-guide.md                  # Multi-agent coordination, dependencies
    ‚îî‚îÄ‚îÄ reporting-guide.md                      # Aggregation, formatting, distribution
```

**SKILL.md CSO Description:**
```yaml
description: Use when creating slash commands, building workflows, need command scaffolding, want /env:command patterns, before writing .claude/commands/*.md, thinking "I need a command template", planning RPIV/validation/batch/ETL/orchestration/reporting workflows - provides 6 specialized templates with validation for diverse workflow patterns
```

**Template Characteristics:**

| Template | Placeholders | Sections | Unique Features |
|----------|--------------|----------|-----------------|
| RPIV | `{{COMMAND_NAME}}`, `{{ARG_1}}`, `{{RESEARCH_STEP_1}}` | 8 | 4 checkpoints, research-first, progress table |
| Validation | `{{CHECK_1_NAME}}`, `{{EXPECTED_RESULT_1}}` | 6 | ‚úÖ‚ö†Ô∏è‚ùå format, no checkpoints, read-only |
| Batch | `{{INPUT_DIR}}`, `{{PATTERN}}`, `{{LOOP_STEP_1}}` | 7 | Per-item errors, progress tracking, summary report |
| Data Transformation | `{{SOURCE_FILE}}`, `{{TRANSFORM_1}}`, `{{QUALITY_CHECK_1}}` | 7 | Load ‚Üí Transform ‚Üí Validate ‚Üí Output pipeline |
| Orchestration | `{{AGENT_1}}`, `{{DEPENDENCY_1}}`, `{{STATE_VAR_1}}` | 8 | Dependency graph, multi-agent coordination, state tracking |
| Reporting | `{{DATA_SOURCE}}`, `{{METRIC_1}}`, `{{FORMAT_1}}` | 7 | Aggregate ‚Üí Analyze ‚Üí Format ‚Üí Distribute |

**Validators:**

1. **validate_command_yaml.py**
   - Required: `description` (‚â§1024 chars)
   - Optional: `model`, `allowed-tools`, `argument-hint`, `disable-model-invocation`
   - Kebab-case check (relaxed for command name, enforced for file)

2. **validate_command_naming.py**
   - File pattern: `^[a-z0-9]+(-[a-z0-9]+)*\.md$`
   - Environment: File in `dev/`, `prod/`, or `shared/` subdir
   - Invocation format: `/env:command-name` documented in usage line

3. **validate_command_structure.py**
   - RPIV: 8 sections (Header, STEP 1-4, Success Criteria, Example, Anti-Patterns)
   - Validation: 6 sections (Header, Checks, Report Format, Usage Example, Anti-Patterns)
   - Batch: 7 sections (Header, Discovery, Loop, Summary, Error Handling, Example, Anti-Patterns)
   - Data Transformation: 7 sections (Header, Load, Transform, Validate, Output, Example, Anti-Patterns)
   - Orchestration: 8 sections (Header, Dependency Graph, Agent Coordination, State Management, Execution, Success Criteria, Example, Anti-Patterns)
   - Reporting: 7 sections (Header, Data Sources, Aggregation, Analysis, Formatting, Distribution, Example)

4. **validate_command_usage.py**
   - Usage line present: `**Usage:** /command <arg1> [arg2]`
   - Arguments match `argument-hint` if specified
   - Positional args documented ($1, $2, $3 if used)

### 6.2 creating-agents Skill

**Directory Structure:**
```
.claude/skills/creating-agents/
‚îú‚îÄ‚îÄ SKILL.md                                    # Main skill (target: <200 lines)
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îÇ       ‚îú‚îÄ‚îÄ AGENT_DOMAIN_SPECIALIST_TEMPLATE.md # ~280 lines, full tools (PRIMARY)
‚îÇ       ‚îú‚îÄ‚îÄ AGENT_RESEARCHER_TEMPLATE.md        # ~280 lines, read+web
‚îÇ       ‚îî‚îÄ‚îÄ AGENT_REVIEWER_TEMPLATE.md          # ~280 lines, read-only
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_agent.py                       # Orchestrator (3 template options)
‚îÇ   ‚îú‚îÄ‚îÄ validate_agent_yaml.py                  # YAML frontmatter
‚îÇ   ‚îú‚îÄ‚îÄ validate_agent_naming.py                # Kebab-case
‚îÇ   ‚îú‚îÄ‚îÄ validate_agent_structure.py             # Required sections (3 templates)
‚îÇ   ‚îî‚îÄ‚îÄ validate_agent_tools.py                 # Tool tier compliance
‚îî‚îÄ‚îÄ references/
    ‚îú‚îÄ‚îÄ domain-specialist-guide.md              # Constrained expertise, comprehensive coverage (PRIMARY)
    ‚îú‚îÄ‚îÄ researcher-patterns.md                  # Investigation structure, web research tools
    ‚îî‚îÄ‚îÄ reviewer-patterns.md                    # Checklist design, read-only verification
```

**SKILL.md CSO Description:**
```yaml
description: Use when creating agents, building subagents, need agent scaffolding, want @agent-name patterns, before writing .claude/agents/*.md, thinking "I need an agent template", planning domain specialist/researcher/reviewer agents - provides 3 validated templates with tool tier enforcement based on 116 production agents
```

**Template Characteristics:**

| Template | Placeholders | Tool Tier | Sections | Pattern Frequency |
|----------|--------------|-----------|----------|-------------------|
| Domain Specialist | `{{DOMAIN}}`, `{{AREA_1_NAME}}` | Full access | 6 | **PRIMARY** (86% of agents) |
| Researcher | `{{RESEARCH_FOCUS}}`, `{{QUERY_1}}` | Read + Web | 6 | Web research (5% of agents) |
| Reviewer | `{{AGENT_NAME}}`, `{{CHECK_1_NAME}}` | Read-only | 6 | Verification (3-5% of agents) |

**All templates use standardized 6-section structure:**
1. Role Statement
2. Communication Protocol (JSON query format)
3. Checklist (8 items)
4. Development Workflow (3 phases: Analysis, Implementation, Excellence)
5. Integration Notes (optional)
6. Anti-Patterns (optional)

**Validators:**

1. **validate_agent_yaml.py**
   - Required: `name` (kebab-case), `description` (100-150 chars)
   - Optional: `tools`, `model`
   - No CSO check (agents use explicit `@name` invocation)

2. **validate_agent_naming.py**
   - File pattern: `^[a-z0-9]+(-[a-z0-9]+)*\.md$`
   - Name matches file (name: `code-reviewer`, file: `code-reviewer.md`)
   - Location: `.claude/agents/` (global, not environment-specific)

3. **validate_agent_structure.py**
   - All templates: 6 major sections
   - Domain Specialist: 8-15 domain areas (subsections)
   - Researcher: Investigation workflow structure
   - Reviewer: Verification checklist structure

4. **validate_agent_tools.py**
   - Reviewer: `tools: [Read, Grep, Glob]` (exactly - read-only)
   - Researcher: `tools: [Read, Grep, Glob, WebFetch, WebSearch]` (exactly - read + web)
   - Domain Specialist: `tools: [Read, Write, Edit, Bash, Glob, Grep]` (exactly - full access)
   - Error if tools don't match template type exactly

---

## Part 7: Key Differences from creating-skills

### 7.1 No CSO Optimization

**Skills:** Auto-invoked based on CSO-optimized description (‚â•0.7 score)
**Commands:** Manual invocation via `/env:command` (no CSO needed)
**Agents:** Manual invocation via `@agent-name` (no CSO needed)

**Implication:**
- **Remove:** validate_cso.py (not applicable)
- **Add:** validate_usage.py (commands), validate_tools.py (agents)
- **Description:** Focus on discoverability in /help menu (commands) or agent list (agents)

### 7.2 No Rationalization-Proofing

**Skills:** Discipline skills need Iron Law, Red Flags, Rationalization table
**Commands:** Workflow structure enforces discipline (RPIV checkpoints)
**Agents:** No workflow enforcement (single-execution review/analysis)

**Implication:**
- **Remove:** validate_rationalization.py (not applicable)
- **Add:** validate_structure.py checks for checkpoints (RPIV commands)

### 7.3 Tool Permissions Critical

**Skills:** Instructional (no tool control)
**Commands:** Optional tool restrictions (`allowed-tools`)
**Agents:** Strong tool tier enforcement (`tools` field)

**Implication:**
- **Add:** validate_agent_tools.py (enforce tool tier by template type)
- **Add:** validate_command_usage.py (check argument-hint matches usage line)

### 7.4 Environment Split

**Skills:** Yes (dev/prod/shared subdirs)
**Commands:** Yes (dev/prod/shared subdirs)
**Agents:** No (global, flat structure)

**Implication:**
- `validate_command_naming.py` checks environment subdir
- `validate_agent_naming.py` checks `.claude/agents/` (no subdir)

---

## Part 8: Implementation Recommendations

### 8.1 Template Development Order

**Phase 1: Primary Templates (Tier 1)**
1. COMMAND_RPIV_TEMPLATE.md (score: 9.8/10) - Proven in variance-analysis.md
2. AGENT_DOMAIN_SPECIALIST_TEMPLATE.md (score: 9.5/10 ‚Üë) - **PRIMARY** agent pattern (86% frequency)
3. COMMAND_VALIDATION_TEMPLATE.md (score: 8.6/10) - Proven in sync-docs.md
4. AGENT_RESEARCHER_TEMPLATE.md (score: 8.6/10 ‚Üë) - Distinct web research pattern

**Phase 2: Supporting Templates (Tier 2)**
5. COMMAND_BATCH_PROCESSING_TEMPLATE.md (score: 8.4/10) - High FP&A demand
6. AGENT_REVIEWER_TEMPLATE.md (score: 7.8/10) - Proven in code-reviewer.md

**Phase 3: Additional Command Templates (Tier 3)**
7. COMMAND_DATA_TRANSFORMATION_TEMPLATE.md (score: 7.8/10) - ETL workflows
8. COMMAND_ORCHESTRATION_TEMPLATE.md (score: 7.5/10) - Multi-agent coordination
9. COMMAND_REPORTING_TEMPLATE.md (score: 7.2/10) - Analytics and dashboards

**Rationale:**
- Tier 1 prioritizes proven patterns (variance-analysis, code-reviewer) and primary agent pattern (86% frequency)
- Tier 2 adds high-demand supporting templates
- Tier 3 covers specialized command workflows
- Agent templates reduced from 6 to 3 based on validation (orchestrator/analyzer/generator removed as redundant/anti-patterns)

### 8.2 Validator Complexity Ranking

**Simple (50-100 lines):**
- validate_command_naming.py (file pattern, environment check)
- validate_agent_naming.py (file pattern, name match)

**Medium (100-150 lines):**
- validate_command_yaml.py (5 fields, 1 required)
- validate_agent_yaml.py (4 fields, 2 required)
- validate_agent_tools.py (tool tier matching)

**Complex (150-300 lines):**
- validate_command_structure.py (6 templates √ó 6-8 sections)
- validate_agent_structure.py (3 templates √ó 6 sections each)
- validate_command_usage.py (usage line parsing, arg matching)

### 8.3 Progressive Disclosure Strategy

**Commands (6 templates, 6 reference guides):**
- Main SKILL.md: 6 sections (Overview, When to Use, Instructions, Pitfalls, Examples, Progressive Disclosure)
- references/rpiv-workflow-guide.md: Deep dive on checkpoints, progress tracking
- references/validation-patterns.md: ‚úÖ‚ö†Ô∏è‚ùå reporting, systematic checks
- references/batch-processing-guide.md: Error handling, loop patterns, summary reports
- references/data-transformation-guide.md: ETL pipelines, data quality gates
- references/orchestration-guide.md: Multi-agent coordination (commands coordinate agents)
- references/reporting-guide.md: Aggregation, formatting, distribution

**Agents (3 templates, 3 reference guides):**
- Main SKILL.md: 6 sections (same as commands)
- references/domain-specialist-guide.md: Constrained expertise, comprehensive coverage (8-15 areas) - **PRIMARY**
- references/researcher-patterns.md: Investigation structure, web research tools
- references/reviewer-patterns.md: Checklist design, read-only verification

**Target:** Main SKILL.md <200 lines, references/ 300-500 lines each

**Removed Guides:**
- ‚ùå orchestrator-patterns.md (anti-pattern - commands coordinate agents)
- ‚ùå analyzer-patterns.md (redundant - use domain-specialist-guide.md)
- ‚ùå generator-patterns.md (redundant - use domain-specialist-guide.md)

---

## Part 9: Testing Strategy

### 9.1 Validator Testing

**Unit Tests (pytest):**
```python
# test_validate_command_yaml.py
def test_missing_description():
    """YAML without description should fail."""
    content = "---\nname: test\n---\n"
    result = validate_yaml(content)
    assert result['passed'] == False
    assert 'description' in str(result['errors'])

def test_description_too_long():
    """Description >1024 chars should warn."""
    content = f"---\ndescription: {'x' * 1025}\n---\n"
    result = validate_yaml(content)
    assert result['exit_code'] == 2  # warning
```

**Integration Tests:**
```python
# test_generate_command.py
def test_rpiv_template_generation():
    """Generate RPIV command and validate all checks pass."""
    result = generate_command(
        name='test-workflow',
        template='rpiv',
        environment='dev',
        description='Test workflow',
        args=['file1', 'file2']
    )
    assert result['success'] == True
    assert Path('.claude/commands/dev/test-workflow.md').exists()
    # Run all validators
    for validator in VALIDATORS:
        assert run_validator(validator, result['path']) == 0
```

### 9.2 Template Testing

**Checklist for Each Template:**
- [ ] All placeholders documented
- [ ] Example replacement values provided
- [ ] Generated file passes all validators
- [ ] Matches external patterns (awesome-claude-code-subagents)
- [ ] Progressive disclosure links work

**Manual Testing:**
1. Generate command/agent from template
2. Fill placeholders manually
3. Invoke command/agent in real scenario
4. Verify output matches expected format
5. Iterate based on usability feedback

---

## Part 10: Success Criteria

### 10.1 creating-commands Skill

**Required Deliverables:**
- [ ] SKILL.md (technique type, <200 lines)
- [ ] 6 templates (RPIV, Validation, Batch Processing, Data Transformation, Orchestration, Reporting)
- [ ] 4 validators (yaml, naming, structure, usage)
- [ ] 1 orchestrator (generate_command.py)
- [ ] 6 reference guides (rpiv, validation, batch, data-transformation, orchestration, reporting)

**Quality Gates:**
- [ ] All validators pass on creating-commands SKILL.md
- [ ] Generated variance-analysis.md from RPIV template passes validators
- [ ] Generated sync-docs.md from Validation template passes validators
- [ ] Manual test: Generate new command, use it successfully

### 10.2 creating-agents Skill

**Required Deliverables:**
- [ ] SKILL.md (technique type, <200 lines)
- [ ] **3 templates** (Domain Specialist, Researcher, Reviewer) - validated against 116 external agents
- [ ] 4 validators (yaml, naming, structure, tools)
- [ ] 1 orchestrator (generate_agent.py with 3 template options)
- [ ] **3 reference guides** (domain-specialist-guide.md, researcher-patterns.md, reviewer-patterns.md)

**Quality Gates:**
- [ ] All validators pass on creating-agents SKILL.md
- [ ] Generated code-reviewer.md from Reviewer template passes validators
- [ ] Generated fintech-engineer.md from Domain Specialist template passes validators (PRIMARY pattern)
- [ ] Generated research-analyst.md from Researcher template passes validators
- [ ] Manual test: Generate new agent, invoke it successfully
- [ ] Validation: All templates use 6 major sections (not 7-12)

**Removed Deliverables:**
- ‚ùå AGENT_ORCHESTRATOR template (anti-pattern - commands coordinate agents)
- ‚ùå AGENT_ANALYZER template (redundant with Domain Specialist)
- ‚ùå AGENT_GENERATOR template (redundant with Domain Specialist)
- ‚ùå orchestrator-patterns.md, analyzer-patterns.md, generator-patterns.md (removed guides)

### 10.3 Integration with creating-skills

**Consistency Checks:**
- [ ] Same directory structure (assets/templates/, scripts/, references/)
- [ ] Same orchestrator pattern (interactive prompts ‚Üí temp dir ‚Üí validate ‚Üí commit)
- [ ] Same validator exit codes (0=pass, 1=error, 2=warning)
- [ ] Same placeholder format (`{{VARIABLE}}`)
- [ ] Same progressive disclosure strategy (main <200 lines, references/ for depth)

---

## Appendix A: File Size Analysis

**Template Sizes (external awesome-claude-code-subagents):**
- Minimum: 200 lines (simple researcher agents)
- Maximum: 315 lines (comprehensive domain specialists)
- Average: 285 lines
- Mode: 285 lines (60% of agents)

**Command Sizes (project):**
- variance-analysis.md: 184 lines (RPIV pattern)
- sync-docs.md: 269 lines (Validation pattern)

**Implication:** Target template sizes:
- **Commands:**
  - COMMAND_RPIV: ~250 lines
  - COMMAND_VALIDATION: ~200 lines
  - COMMAND_BATCH: ~230 lines
  - COMMAND_DATA_TRANSFORMATION: ~220 lines
  - COMMAND_ORCHESTRATION: ~240 lines
  - COMMAND_REPORTING: ~210 lines
- **Agents (standardized to 275-285 line range):**
  - AGENT_DOMAIN_SPECIALIST: ~280 lines (PRIMARY)
  - AGENT_RESEARCHER: ~280 lines
  - AGENT_REVIEWER: ~280 lines

---

## Appendix B: Placeholder Naming Conventions

**Command Placeholders:**
```
{{COMMAND_NAME}}              # Kebab-case name (variance-analysis)
{{COMMAND_TITLE}}             # Human-readable title (Variance Analysis Command)
{{ENVIRONMENT}}               # dev, prod, shared
{{ARG_1}}, {{ARG_2}}          # Positional arguments
{{DESCRIPTION}}               # Help menu description
{{RESEARCH_STEP_1}}           # RPIV template steps
{{CHECK_1_NAME}}              # Validation template checks
{{INPUT_DIR}}, {{PATTERN}}    # Batch template parameters
```

**Agent Placeholders:**
```
{{AGENT_NAME}}                # Kebab-case name (code-reviewer)
{{AGENT_TITLE}}               # Human-readable title (Code Reviewer)
{{ROLE_DESCRIPTION}}          # "You are a senior..."
{{DOMAIN}}                    # Financial systems, Python ecosystem
{{CHECK_1_NAME}}              # Checklist items
{{AREA_1_NAME}}               # Domain areas (Banking, Payments, etc.)
{{TOOL_TIER}}                 # read-only, read+web, full
```

---

## Appendix C: External References

**Official Documentation:**
- docs.claude.com/en/docs/claude-code/slash-commands
- docs.claude.com/en/docs/claude-code/agents

**External Repos:**
- awesome-claude-code-subagents: 116 production agents
- 12-factor-agents: Principles for reliable LLM apps

**Project Files:**
- .claude/skills/creating-skills/ (proven meta-skill architecture)
- .claude/commands/prod/variance-analysis.md (RPIV example)
- .claude/commands/shared/sync-docs.md (Validation example)
- .claude/agents/code-reviewer.md (Reviewer example)
- specs/commands-and-agents/research.md (command/agent patterns)
- specs/commands-and-agents/multi-agent-analysis.md (template validation)

---

---

## Appendix D: Template Details and Validation

**CRITICAL UPDATE:** Based on deep validation against 116 external agents + 12-factor-agents principles, agent templates reduced from 6 to 3.
See `research-validation-addendum.md` for complete 50+ source validation analysis.

### D.1 Command Templates (6 Templates - All Validated)

**4. COMMAND_DATA_TRANSFORMATION_TEMPLATE.md (Score: 7.8/10)**

**Use Cases:**
- ETL pipelines (Extract, Transform, Load)
- Data format conversions (CSV ‚Üî Excel ‚Üî JSON)
- Data migration between systems
- Data quality improvement workflows

**Structure (7 sections):**
```markdown
# Data Transformation Command

## Phase 1: Load Data
- Validate source file format
- Check schema/structure
- Document data profile

## Phase 2: Transform Data
- Apply transformation rules
- Handle edge cases (NULL, duplicates)
- Track transformation metrics

## Phase 3: Validate Output
- Data quality checks
- Completeness verification
- Accuracy validation

## Phase 4: Output
- Write to target format
- Generate audit trail
- Create summary report
```

**Key Differentiators vs RPIV:**
- No research phase (transformation rules are known)
- Focus on data quality gates
- Pipeline-oriented (Load ‚Üí Transform ‚Üí Validate ‚Üí Output)
- No human checkpoints (automated workflow)

**External Validation:** data-analyst pattern (transformation focus)

---

**5. COMMAND_ORCHESTRATION_TEMPLATE.md (Score: 7.5/10)**

**Use Cases:**
- Multi-agent coordination workflows
- Complex approval chains
- Dependency-driven processes
- State machine implementations

**Structure (8 sections):**
```markdown
# Orchestration Command

## Phase 1: Define Dependency Graph
- List agents/tasks
- Document dependencies
- Define execution order

## Phase 2: Initialize State
- Set up state variables
- Define transition rules
- Create monitoring structure

## Phase 3: Coordinate Execution
- Invoke agents in order
- Track state transitions
- Handle failures gracefully

## Phase 4: Aggregate Results
- Collect outputs from all agents
- Validate completion criteria
- Generate consolidated report
```

**Key Differentiators vs RPIV:**
- Manages multiple agents (not single workflow)
- Dependency tracking (execution order based on dependencies)
- State management (persistent state across agent invocations)
- Coordination focus (vs research/implementation focus)

**External Validation:** workflow-orchestrator, task-distributor patterns

---

**6. COMMAND_REPORTING_TEMPLATE.md (Score: 7.2/10)**

**Use Cases:**
- Executive dashboards
- Financial reports (variance, P&L, balance sheet)
- Analytics summaries
- KPI tracking reports

**Structure (7 sections):**
```markdown
# Reporting Command

## Phase 1: Define Data Sources
- Identify source files/databases
- Document required metrics
- Define aggregation rules

## Phase 2: Aggregate Data
- Load all data sources
- Apply aggregation logic
- Calculate derived metrics

## Phase 3: Analyze Trends
- Identify patterns
- Calculate variances
- Flag anomalies

## Phase 4: Format Report
- Apply formatting rules
- Generate visualizations (tables, charts)
- Add executive summaries

## Phase 5: Distribute
- Output to multiple formats (Excel, PDF, HTML)
- Send to distribution list
- Archive with timestamp
```

**Key Differentiators vs RPIV:**
- Aggregation focus (combine multiple sources)
- Multi-format output (Excel + PDF + HTML)
- Distribution channels (email, shared drive, etc.)
- No implementation phase (presentation-focused)

**External Validation:** data-analyst, business-analyst patterns (reporting specialization)

---

### D.2 Agent Templates (3 Templates - Validated Against 116 External Agents)

**VALIDATION SUMMARY:**
- ‚úÖ **KEPT:** 3 templates (DOMAIN_SPECIALIST, RESEARCHER, REVIEWER) - architecturally distinct tool tiers
- ‚ùå **REMOVED:** 3 templates (ORCHESTRATOR, ANALYZER, GENERATOR) - anti-patterns or redundancies
- **Evidence:** 116 external agents in awesome-claude-code-subagents + 12-factor-agents principles

**1. AGENT_DOMAIN_SPECIALIST_TEMPLATE.md (Score: 9.5/10 ‚Üë) - PRIMARY**

**Pattern Frequency:** 100+ agents (86% of total) üåü

**Use Cases (Validated from External Agents):**
- Language expertise: python-pro, typescript-pro, rust-engineer (23 agents)
- Domain expertise: fintech-engineer, quant-analyst, healthcare-specialist (18 agents)
- Infrastructure: kubernetes-specialist, cloud-architect (12 agents)
- **Data analysis:** data-analyst, data-scientist (12 agents) - was "Analyzer"
- **Artifact generation:** cli-developer, tooling-engineer (10 agents) - was "Generator"

**Structure (6 major sections - STANDARDIZED):**
```markdown
# Role Statement (1-2 paragraphs)
You are a [seniority] [domain] specialist with expertise in [areas]...

## Communication Protocol
### Context Query Format (JSON)
{
  "requesting_agent": "domain-specialist-name",
  "requirements": "..."
}

## Checklist (8 items)
- [ ] Domain criterion 1 verified
- [ ] Domain criterion 2 achieved
...

## Development Workflow
### Phase 1: Analysis
- Understand requirements
- Review existing state
### Phase 2: Implementation
- Execute domain-specific work
- Track progress
### Phase 3: Excellence Delivery
- Validate quality
- Document results

## Integration Notes (Optional)
Work with:
- @related-agent-1 on [task]
...

## Anti-Patterns (Optional)
‚ùå Bad practice 1
‚úÖ Good practice 1
```

**Tool Tier:** Full access - `[Read, Write, Edit, Bash, Glob, Grep]` (100% consistency across 100+ agents)

**Key Insights:**
- **THIS IS THE PRIMARY TEMPLATE** - use for 86% of agent needs
- data-analyst is NOT a separate template, it's a domain specialist in data analysis
- cli-developer is NOT a separate template, it's a domain specialist in CLI development
- External agents classify these as "domain specialists" not separate categories

**External Examples:**
- `/external/awesome-claude-code-subagents/categories/02-language-specialists/python-pro.md`
- `/external/awesome-claude-code-subagents/categories/07-specialized-domains/fintech-engineer.md`
- `/external/awesome-claude-code-subagents/categories/05-data-ai/data-analyst.md` (was "analyzer")
- `/external/awesome-claude-code-subagents/categories/06-developer-experience/cli-developer.md` (was "generator")

---

**2. AGENT_RESEARCHER_TEMPLATE.md (Score: 8.6/10 ‚Üë)**

**Pattern Frequency:** 6 agents (5% of total, 100% tool consistency)

**Use Cases (Validated from External Agents):**
- competitive-analyst.md (competitive intelligence)
- data-researcher.md (data source discovery)
- market-researcher.md (market analysis)
- research-analyst.md (general research)
- search-specialist.md (information retrieval)
- trend-analyst.md (trend identification)

**Structure (6 major sections):**
Same as Domain Specialist, but with investigation-focused workflow.

**Tool Tier:** Read + Web - `[Read, Grep, Glob, WebFetch, WebSearch]` (100% consistency across 6 agents)

**Key Differentiator:**
- **ONLY template with web research tools** (WebFetch, WebSearch)
- Architecturally distinct from Domain Specialist (different tools = different permissions)
- Discovery focus (NOT transformation like analysts)

---

**3. AGENT_REVIEWER_TEMPLATE.md (Score: 7.8/10 ‚Üì)**

**Pattern Frequency:** 4-6 agents (3-5% of total)

**Use Cases (Validated from External Agents):**
- code-reviewer.md (code quality verification)
- security-auditor.md (security compliance)
- architect-reviewer.md (architecture review)
- compliance-auditor.md (regulatory compliance)

**Structure (6 major sections):**
Same as Domain Specialist, but with verification-focused workflow and APPROVE/REJECT output.

**Tool Tier:** Read-only - `[Read, Grep, Glob]` (100% consistency across reviewers)

**Key Differentiator:**
- **Read-only by security design** (no code modification)
- Architecturally distinct from Domain Specialist (different tools = different permissions)
- Verification focus with structured output (CRITICAL/WARNING/SUGGESTION, APPROVE/REJECT)

**Note:** Project code-reviewer.md uses this pattern.

---

### D.3 Removed Templates (Anti-Patterns and Redundancies)

**‚ùå AGENT_ORCHESTRATOR (Anti-Pattern)**

**Why Removed:**
1. **Context Isolation Violation:** Agents operate in separate contexts (code-reviewer.md:254), cannot communicate
2. **No Task Tool:** Task tool for coordination is SDK-only, NOT available in `.claude/agents/`
3. **Duplicates Command Functionality:** Orchestration is what COMMANDS do (variance-analysis.md invokes @code-reviewer)
4. **12-Factor Violation:** Factor 10 states "agents are building blocks in a larger, mostly deterministic system" - the system = COMMAND

**Evidence:**
- `/external/12-factor-agents/content/factor-10-small-focused-agents.md`: "Agents are just one building block"
- `/external/awesome-claude-code-subagents/categories/09-meta-orchestration/` agents assume SDK context
- Project variance-analysis.md (COMMAND) invokes @code-reviewer (AGENT) at checkpoints

**Replacement:** Use **COMMAND_ORCHESTRATION_TEMPLATE** instead (commands coordinate agents).

---

**‚ùå AGENT_ANALYZER (Redundant with Domain Specialist)**

**Why Removed:**
1. **Same Tools:** Read, Write, Edit, Bash, Glob, Grep (identical to Domain Specialist)
2. **Same Structure:** 6 sections, 275-285 lines, 3-phase workflow
3. **Same Pattern:** External agents classify data-analyst AS a domain specialist
4. **Content vs Structure:** "Analysis" is domain content, not template structure

**Evidence:**
- `/external/awesome-claude-code-subagents/categories/05-data-ai/data-analyst.md` - uses Domain Specialist pattern
- Tools are identical to python-pro, fintech-engineer, kubernetes-specialist
- 12 data/AI agents ALL use Domain Specialist structure

**Replacement:** Use **AGENT_DOMAIN_SPECIALIST_TEMPLATE** with data analysis domain areas.

---

**‚ùå AGENT_GENERATOR (Redundant with Domain Specialist)**

**Why Removed:**
1. **Same Tools:** Read, Write, Edit, Bash, Glob, Grep (identical to Domain Specialist)
2. **Same Structure:** 6 sections, 275-285 lines, 3-phase workflow
3. **Same Pattern:** External agents classify cli-developer AS a domain specialist
4. **Content vs Structure:** "Generation" is domain content, not template structure

**Evidence:**
- `/external/awesome-claude-code-subagents/categories/06-developer-experience/cli-developer.md` - uses Domain Specialist pattern
- Tools are identical to python-pro, fintech-engineer, data-analyst
- 10 developer experience agents ALL use Domain Specialist structure

**Replacement:** Use **AGENT_DOMAIN_SPECIALIST_TEMPLATE** with CLI/artifact generation domain areas.

---

### D.4 Scoring Rationale

**Command Template Scores:**
- RPIV (9.8/10): Proven in production (variance-analysis.md), multi-agent consensus
- Validation (8.6/10): Proven in production (sync-docs.md), clear use cases
- Batch (8.4/10): High FP&A user demand, external validation
- **Data Transformation (7.8/10):** Distinct from RPIV (no research), data-analyst pattern, FP&A ETL needs
- **Orchestration (7.5/10):** Workflow-orchestrator pattern, multi-agent coordination unique
- **Reporting (7.2/10):** Previously 6.4/10, upgraded with distinct aggregation/formatting/distribution focus

**Agent Template Scores (REVISED after 50+ source validation):**
- **Domain Specialist (9.5/10 ‚Üë):** PRIMARY template - 86% frequency, 100+ agents, gold standard pattern
- **Researcher (8.6/10 ‚Üë):** Distinct web research tools, 100% tool consistency across 6 agents
- **Reviewer (7.8/10 ‚Üì):** Niche but critical (3-5%), read-only security constraint, proven in code-reviewer.md
- ‚ùå ~~Orchestrator (N/A):~~ **REMOVED** - Anti-pattern (commands coordinate agents, not agents)
- ‚ùå ~~Analyzer (6.2/10):~~ **REMOVED** - Redundant (data-analyst IS a domain specialist)
- ‚ùå ~~Generator (6.0/10):~~ **REMOVED** - Redundant (cli-developer IS a domain specialist)

**Final Template Count:**
- **Commands:** 6 templates (all validated against project patterns and FP&A needs)
- **Agents:** 3 templates (validated against 116 external agents + 12-factor principles)
- **Total:** 9 templates (down from 12 originally proposed)

**Validation Rigor:**
- 116 external agents analyzed for patterns
- 12-factor-agents architectural principles applied
- Claude Code implementation examined (variance-analysis.md, code-reviewer.md)
- Tool tier consistency verified (100% match for Domain Specialist and Researcher)
- Section count standardized (6 major sections for all agents)
- Anti-patterns identified and removed (orchestrator context violation)
- Redundancies eliminated (analyzer/generator merged into domain specialist)

---

**END OF RESEARCH**

Research phase complete. Ready for CHECKPOINT 1: Present findings to user for approval before planning.
