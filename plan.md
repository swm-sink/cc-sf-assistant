# FP&A Automation Assistant - Technical Planning Document

**Version:** 1.0-DRAFT
**Last Updated:** 2025-11-08
**Status:** üöß IN PLANNING
**References:** spec.md (business requirements), CLAUDE.md (behavioral rules)

**Key Principle:** spec.md defines WHAT to build. This document defines HOW to build it.

---

## Table of Contents

1. [Technology Stack](#technology-stack)
2. [Architecture Overview](#architecture-overview)
3. [Implementation Strategy](#implementation-strategy)
4. [Directory Structure](#directory-structure)
5. [Code Quality Standards](#code-quality-standards)
6. [Testing Strategy](#testing-strategy)
7. [Deployment Approach](#deployment-approach)
8. [Performance Considerations](#performance-considerations)
9. [Security & Compliance](#security--compliance)
10. [Development Workflow](#development-workflow)

---

## Technology Stack

### Core Languages & Runtime

**Python 3.11+**
- Rationale: Industry standard for data processing, extensive library ecosystem
- Decimal type built-in for financial precision
- Type hints support for code quality
- Async/await for potential concurrent operations

### Required Dependencies

```python
# Core Data Processing
pandas==2.2.0                    # DataFrame operations [VERIFIED: Latest stable]
numpy==1.26.3                    # Numerical computations (NOT for currency)
openpyxl==3.1.2                  # Excel read/write (.xlsx)
xlrd==2.0.1                      # Legacy Excel (.xls) if needed

# Google Workspace Integration
gspread==6.1.2                   # Google Sheets API
google-auth==2.35.0              # Authentication
google-api-python-client==2.150.0  # Slides/Drive API

# Presentation & Reporting
python-pptx==1.0.2               # PowerPoint generation (if needed)
matplotlib==3.9.2                # Static charts
plotly==5.24.1                   # Interactive dashboards (optional)

# Utilities
python-dotenv==1.0.1             # Environment configuration
pyyaml==6.0.1                    # Config file parsing
typing-extensions==4.9.0         # Extended type hints

# Development & Testing (Modernized - November 2025)
pytest==7.4.3                    # Testing framework
pytest-cov==4.1.0                # Coverage reporting
mypy==1.8.0                      # Static type checking
ruff==0.14.4                     # Fast linting, formatting, security (replaces Black, Flake8, isort, bandit)
```

**Tools Modernization Note:**
- Ruff (v0.14.4) replaces: Black, Flake8, isort, bandit, pyupgrade
- 200x faster than traditional tools
- Single tool for linting, formatting, import sorting, security checks

### Version Management

**Tool:** `pyenv` for Python version management
**Approach:** Pin all dependencies to exact versions in `requirements.txt`
**Updates:** Review quarterly for security patches

---

## Architecture Overview

### Separation of Concerns

Following Anthropic best practices for Claude Code projects:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Configuration Layer                  ‚îÇ
‚îÇ  - spec.md (WHAT to build)                             ‚îÇ
‚îÇ  - plan.md (HOW to build - this document)             ‚îÇ
‚îÇ  - CLAUDE.md (behavioral rules)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                 ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Skills     ‚îÇ ‚îÇ  Commands    ‚îÇ ‚îÇ   Agents     ‚îÇ
‚îÇ (Auto)       ‚îÇ ‚îÇ  (Manual)    ‚îÇ ‚îÇ (Sub)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                 ‚îÇ                 ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 Implementation Layer                    ‚îÇ
‚îÇ  /src                                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ core/           (business logic)                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ integrations/   (external APIs)                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ reporting/      (output generation)               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ utils/          (helpers)                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Data Layer                          ‚îÇ
‚îÇ  /data                                                  ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ input/          (source files - git-ignored)      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ output/         (generated reports - git-ignored) ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ templates/      (report templates - versioned)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Architectural Patterns

**1. Progressive Disclosure (Skills)**
- Metadata loaded at startup
- Full content loaded on-demand
- Reduces token usage, improves performance

**2. Human-in-Loop (Commands)**
- Checkpoints at decision points
- Prevents automated errors
- Maintains user control

**3. Context Isolation (Agents)**
- Independent verification
- Unbiased code review
- Separate tool access

**4. Quality Gates (Hooks)**
- Automated enforcement
- No reliance on model memory
- Fail-fast on critical issues

---

## Implementation Strategy

### Epic 1: Monthly Close Automation

#### Story 1.1: Multi-Department Data Consolidation

**Technical Approach:**

1. **File Discovery**
```python
# src/core/file_discovery.py
from pathlib import Path
from typing import List, Dict

def discover_excel_files(folder_path: str) -> List[Path]:
    """
    Discover all Excel files in folder.

    Returns:
        List of Path objects for .xlsx and .xls files
    """
    path = Path(folder_path)
    excel_files = list(path.glob("*.xlsx")) + list(path.glob("*.xls"))
    return sorted(excel_files)  # Deterministic order
```

2. **Structure Validation**
```python
# Uses financial-validator skill
from decimal import Decimal
import pandas as pd

def validate_department_file(
    file_path: Path,
    required_columns: List[str]
) -> Tuple[bool, List[str]]:
    """
    Validate department file structure.

    Returns:
        (is_valid, list_of_issues)
    """
    # Load file
    df = pd.read_excel(file_path, engine='openpyxl')

    issues = []

    # Check required columns
    missing = set(required_columns) - set(df.columns)
    if missing:
        issues.append(f"Missing columns: {missing}")

    # Check data types
    # Validate amounts are numeric
    # Flag NULL values

    return len(issues) == 0, issues
```

3. **Account Mapping**
```python
# config/account_mapping.yaml loaded via PyYAML
# Maps department-specific codes to corporate chart of accounts

def map_account_codes(
    department_df: pd.DataFrame,
    mapping_config: Dict[str, str]
) -> pd.DataFrame:
    """
    Map department account codes to corporate codes.

    Uses account_mapping.yaml configuration.
    """
    df = department_df.copy()
    df['corporate_account'] = df['account_code'].map(mapping_config)

    # Flag unmapped accounts
    unmapped = df[df['corporate_account'].isna()]
    if not unmapped.empty:
        # Log warning, create reconciliation report
        pass

    return df
```

4. **Consolidation**
```python
def consolidate_departments(
    files: List[Path],
    mapping_config: Dict
) -> Tuple[pd.DataFrame, Dict]:
    """
    Consolidate all department files.

    Returns:
        (consolidated_df, metadata)
    """
    all_data = []
    metadata = {
        'source_files': [],
        'records_per_file': {},
        'unmatched_accounts': [],
        'timestamp': datetime.now(UTC).isoformat()
    }

    for file in files:
        df = load_and_validate(file)
        df = map_account_codes(df, mapping_config)
        df['source_file'] = str(file)

        all_data.append(df)
        metadata['source_files'].append(str(file))
        metadata['records_per_file'][str(file)] = len(df)

    consolidated = pd.concat(all_data, ignore_index=True)

    return consolidated, metadata
```

**Testing Approach:**
- Unit tests for each function with edge cases
- Integration test with sample department files
- Reconciliation report validation

---

#### Story 2.1: Budget vs. Actual Variance Calculation

**Technical Approach:**

```python
# src/core/variance_calculator.py
from decimal import Decimal, ROUND_HALF_UP
from typing import Tuple, Optional, Literal

def calculate_variance(
    actual: Decimal,
    budget: Decimal,
    account_type: Literal['revenue', 'expense', 'asset', 'liability']
) -> Tuple[Decimal, Optional[Decimal], bool, str]:
    """
    Calculate financial variance with edge case handling.

    Args:
        actual: Actual amount (Decimal required)
        budget: Budget amount (Decimal required)
        account_type: Type for favorability logic

    Returns:
        (absolute_variance, percentage_variance, is_favorable, status)

    Raises:
        TypeError: If actual or budget are not Decimal
        ValueError: If account_type invalid
    """
    # Type validation (enforced by financial-validator skill)
    if not isinstance(actual, Decimal):
        raise TypeError(f"actual must be Decimal, got {type(actual)}")
    if not isinstance(budget, Decimal):
        raise TypeError(f"budget must be Decimal, got {type(budget)}")

    # Calculate absolute variance
    absolute_variance = actual - budget

    # Calculate percentage variance (handle zero division)
    if budget == Decimal('0'):
        if actual == Decimal('0'):
            percentage_variance = Decimal('0')
            status = "No Activity"
        else:
            percentage_variance = None  # Cannot calculate
            status = "Zero Budget - Flag for Review"
    else:
        pct = (absolute_variance / budget) * Decimal('100')
        percentage_variance = pct.quantize(
            Decimal('0.01'),
            rounding=ROUND_HALF_UP
        )
        status = "Normal"

    # Determine favorability
    if account_type == 'revenue':
        is_favorable = (actual > budget)
    elif account_type == 'expense':
        is_favorable = (actual < budget)
    elif account_type == 'asset':
        is_favorable = (actual > budget)
    elif account_type == 'liability':
        is_favorable = (actual < budget)
    else:
        raise ValueError(f"Invalid account_type: {account_type}")

    return absolute_variance, percentage_variance, is_favorable, status
```

**Testing Requirements:**
- Edge cases from `.claude/skills/financial-validator/references/edge-cases.md`
- All 10 categories must pass
- Type enforcement validated
- Decimal precision verified

---

### Epic 3: Management Reporting

#### Story 3.1: Variance Report Generation

**Technical Approach:**

```python
# src/reporting/excel_report_builder.py
from openpyxl import Workbook
from openpyxl.styles import Font, PatternFill, numbers
from typing import Dict

def create_variance_report(
    variance_data: pd.DataFrame,
    output_path: str,
    metadata: Dict
) -> None:
    """
    Generate Excel workbook with variance analysis.

    Sheets:
    1. Executive Summary
    2. Detailed Variance Analysis
    3. Material Variances Only
    4. Metadata/Audit Trail
    """
    wb = Workbook()

    # Sheet 1: Executive Summary
    ws_summary = wb.active
    ws_summary.title = "Executive Summary"
    create_summary_sheet(ws_summary, variance_data)

    # Sheet 2: Detailed Analysis
    ws_detail = wb.create_sheet("Detailed Analysis")
    create_detail_sheet(ws_detail, variance_data)

    # Sheet 3: Material Variances
    ws_material = wb.create_sheet("Material Variances")
    material_data = variance_data[variance_data['is_material'] == True]
    create_material_sheet(ws_material, material_data)

    # Sheet 4: Metadata
    ws_meta = wb.create_sheet("Metadata")
    create_metadata_sheet(ws_meta, metadata)

    # Apply conditional formatting
    apply_conditional_formatting(ws_detail)

    # Save
    wb.save(output_path)
```

**Conditional Formatting Rules:**
- Green: Favorable & Material
- Red: Unfavorable & Material
- Yellow: Favorable but Immaterial
- Gray: Unfavorable but Immaterial

---

## Directory Structure

```
fpa-automation-assistant/
‚îú‚îÄ‚îÄ spec.md                      # WHAT to build (business requirements)
‚îú‚îÄ‚îÄ plan.md                      # HOW to build (this document)
‚îú‚îÄ‚îÄ CLAUDE.md                    # Behavioral configuration
‚îú‚îÄ‚îÄ README.md                    # Project overview
‚îÇ
‚îú‚îÄ‚îÄ .claude/                     # Claude Code configuration
‚îÇ   ‚îú‚îÄ‚îÄ skills/                  # Auto-invoked capabilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financial-validator/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SKILL.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ references/edge-cases.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scripts/validate_precision.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excel-extractor/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ variance-calculator/
‚îÇ   ‚îú‚îÄ‚îÄ commands/                # Manual slash commands
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variance-analysis.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consolidate-data.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ update-slides.md
‚îÇ   ‚îú‚îÄ‚îÄ agents/                  # Subagents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ code-reviewer.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data-analyst.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ research-specialist.md
‚îÇ   ‚îî‚îÄ‚îÄ hooks/                   # Quality gates
‚îÇ       ‚îú‚îÄ‚îÄ stop.sh
‚îÇ       ‚îî‚îÄ‚îÄ pre-commit.sh
‚îÇ
‚îú‚îÄ‚îÄ src/                         # Implementation
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variance_calculator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financial_metrics.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_validator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ account_mapper.py
‚îÇ   ‚îú‚îÄ‚îÄ integrations/            # External systems
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excel_handler.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ google_sheets_client.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ google_slides_client.py
‚îÇ   ‚îú‚îÄ‚îÄ reporting/               # Output generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excel_report_builder.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chart_generator.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/                   # Helpers
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ config_loader.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îî‚îÄ‚îÄ file_utils.py
‚îÇ
‚îú‚îÄ‚îÄ config/                      # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ fpa_config.yaml          # Business rules (thresholds, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ account_mapping.yaml     # Chart of accounts mapping
‚îÇ   ‚îú‚îÄ‚îÄ .env.example             # Environment template
‚îÇ   ‚îî‚îÄ‚îÄ credentials.json         # Google service account (git-ignored)
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Data files (git-ignored except templates)
‚îÇ   ‚îú‚îÄ‚îÄ input/                   # Source files
‚îÇ   ‚îú‚îÄ‚îÄ output/                  # Generated reports
‚îÇ   ‚îî‚îÄ‚îÄ templates/               # Report templates (versioned)
‚îÇ       ‚îú‚îÄ‚îÄ variance_report_template.xlsx
‚îÇ       ‚îî‚îÄ‚îÄ board_presentation_template.pptx
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Test suite
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ unit/                    # Unit tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_variance_calculator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_data_validator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_financial_metrics.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/             # Integration tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_consolidation_workflow.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_variance_analysis_e2e.py
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/                # Test data
‚îÇ       ‚îú‚îÄ‚îÄ sample_budget.xlsx
‚îÇ       ‚îî‚îÄ‚îÄ sample_actuals.xlsx
‚îÇ
‚îú‚îÄ‚îÄ logs/                        # Application logs (git-ignored)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ requirements.txt             # Python dependencies
‚îú‚îÄ‚îÄ requirements-dev.txt         # Development dependencies
‚îú‚îÄ‚îÄ setup.py or pyproject.toml   # Package configuration
‚îî‚îÄ‚îÄ Makefile                     # Common commands
```

---

## Code Quality Standards

### Type Hints (MANDATORY)

```python
from decimal import Decimal
from typing import Dict, List, Optional, Tuple, Literal
from datetime import datetime

def calculate_variance(
    actual: Decimal,
    budget: Decimal,
    account_type: Literal['revenue', 'expense', 'asset', 'liability']
) -> Tuple[Decimal, Optional[Decimal], bool, str]:
    """Full type hints on ALL functions."""
    pass
```

### Docstring Format (Google Style)

```python
def consolidate_departments(
    files: List[Path],
    mapping_config: Dict[str, str]
) -> Tuple[pd.DataFrame, Dict]:
    """
    Consolidate department Excel files into single DataFrame.

    Args:
        files: List of Path objects to Excel files
        mapping_config: Dict mapping dept codes to corporate codes

    Returns:
        Tuple of (consolidated_dataframe, metadata_dict)

    Raises:
        FileNotFoundError: If file in list doesn't exist
        ValueError: If file structure validation fails

    Example:
        >>> files = [Path("sales.xlsx"), Path("marketing.xlsx")]
        >>> mapping = {"S001": "4000", "M001": "6000"}
        >>> df, meta = consolidate_departments(files, mapping)
    """
    pass
```

### Error Handling Pattern

```python
import logging
from typing import Any

logger = logging.getLogger(__name__)

class FinancialCalculationError(Exception):
    """Base exception for financial calculation errors."""
    pass

class DivisionByZeroError(FinancialCalculationError):
    """Raised when attempting to divide by zero budget."""
    pass

class InvalidAccountTypeError(FinancialCalculationError):
    """Raised when account type is not recognized."""
    pass

def safe_calculation(actual: Decimal, budget: Decimal) -> Decimal:
    """
    Perform calculation with comprehensive error handling.
    """
    try:
        if budget == Decimal('0'):
            logger.warning(f"Zero budget detected: actual={actual}")
            raise DivisionByZeroError(
                f"Cannot calculate percentage with zero budget. "
                f"Actual: {actual}, Budget: {budget}"
            )

        result = (actual / budget) * Decimal('100')

        logger.info(f"Calculation successful: {result}%")
        return result

    except DivisionByZeroError:
        # Re-raise custom exceptions
        raise
    except Exception as e:
        # Catch unexpected errors, log with context
        logger.error(
            f"Unexpected error in calculation: {e}",
            extra={'actual': str(actual), 'budget': str(budget)}
        )
        raise FinancialCalculationError(
            f"Calculation failed: {e}"
        ) from e
```

### Logging Standards

```python
import logging
from datetime import datetime, UTC

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/fpa_assistant.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Usage
logger.info(
    "Variance calculated",
    extra={
        'account': account_code,
        'absolute_variance': str(abs_var),
        'percentage_variance': str(pct_var) if pct_var else 'N/A',
        'is_favorable': is_favorable,
        'timestamp': datetime.now(UTC).isoformat()
    }
)
```

---

## Testing Strategy

**CRITICAL REQUIREMENT:** 95%+ test coverage enforced by pre-commit hooks. TDD (Test-Driven Development) is MANDATORY for all financial calculation scripts.

### Test-Driven Development (TDD) Workflow

**Reference:** [.claude/templates/workflows/TDD_WORKFLOW.md](.claude/templates/workflows/TDD_WORKFLOW.md)

**Phases:**
1. **RED** - Write failing tests first
2. **GREEN** - Implement minimal code to pass tests
3. **REFACTOR** - Add type hints, docstrings, error handling, audit logging
4. **VALIDATE** - Independent code-reviewer agent verifies implementation

**Enforcement:**
- Pre-commit hook blocks commits with <95% coverage
- TDD workflow template enforced by skills
- Code generated without TDD is rejected

### Unit Testing

**Coverage Target:** 95%+ for all modules (ENFORCED)

```python
# tests/unit/test_variance_calculator.py
import pytest
from decimal import Decimal
from src.core.variance_calculator import calculate_variance

class TestVarianceCalculator:
    """Comprehensive unit tests for variance calculations."""

    def test_normal_revenue_variance(self):
        """Test standard revenue variance calculation."""
        abs_var, pct_var, is_fav, status = calculate_variance(
            Decimal('115000'),
            Decimal('100000'),
            'revenue'
        )

        assert abs_var == Decimal('15000')
        assert pct_var == Decimal('15.00')
        assert is_fav == True
        assert status == "Normal"

    def test_zero_budget_zero_actual(self):
        """Test edge case: both values zero."""
        abs_var, pct_var, is_fav, status = calculate_variance(
            Decimal('0'),
            Decimal('0'),
            'expense'
        )

        assert abs_var == Decimal('0')
        assert pct_var == Decimal('0')
        assert status == "No Activity"

    def test_float_rejection(self):
        """Test that float types are rejected."""
        with pytest.raises(TypeError, match="must be Decimal"):
            calculate_variance(
                115000.00,  # float - should fail
                Decimal('100000'),
                'revenue'
            )

    @pytest.mark.parametrize("account_type,actual,budget,expected_favorable", [
        ('revenue', Decimal('110'), Decimal('100'), True),
        ('revenue', Decimal('90'), Decimal('100'), False),
        ('expense', Decimal('90'), Decimal('100'), True),
        ('expense', Decimal('110'), Decimal('100'), False),
        ('asset', Decimal('110'), Decimal('100'), True),
        ('liability', Decimal('90'), Decimal('100'), True),
    ])
    def test_favorability_logic(
        self, account_type, actual, budget, expected_favorable
    ):
        """Test favorability for all account types."""
        _, _, is_fav, _ = calculate_variance(actual, budget, account_type)
        assert is_fav == expected_favorable
```

### Integration Testing

```python
# tests/integration/test_variance_analysis_e2e.py
import pytest
from pathlib import Path
from src.core.variance_analyzer import VarianceAnalyzer

class TestVarianceAnalysisEndToEnd:
    """End-to-end integration tests."""

    @pytest.fixture
    def sample_files(self, tmp_path):
        """Create sample budget and actuals files."""
        budget_file = tmp_path / "budget.xlsx"
        actuals_file = tmp_path / "actuals.xlsx"

        # Create sample files with test data
        # ... (file creation logic)

        return budget_file, actuals_file

    def test_full_workflow(self, sample_files):
        """Test complete variance analysis workflow."""
        budget_file, actuals_file = sample_files
        output_file = Path("tests/output/variance_report.xlsx")

        analyzer = VarianceAnalyzer()
        result = analyzer.analyze(
            budget_file=str(budget_file),
            actuals_file=str(actuals_file),
            output_file=str(output_file)
        )

        assert result.success == True
        assert output_file.exists()
        assert result.material_variances_count > 0

        # Verify output structure
        # ... (detailed assertions)
```

### Edge Case Testing

**All edge cases from `.claude/skills/financial-validator/references/edge-cases.md` MUST pass:**

1. Float precision errors
2. Division by zero (3 scenarios)
3. Negative values
4. NULL/missing data
5. Concurrent transactions
6. Multi-currency
7. Rounding precision
8. Boundary conditions
9. Data type mismatches
10. Large numbers/overflow

**Validation Script:**
Run before every commit:
```bash
python .claude/skills/financial-validator/scripts/validate_precision.py
```

### Production-Level Testing Patterns

**Research Sources (November 2025):**
- **FinancePy** (GitHub - domokane/FinancePy) - Derivatives pricing library with comprehensive test coverage
- **PreciseMoney** (GitHub - ListfulAl/PreciseMoney) - Decimal precision enforcement patterns
- **pytest best practices** (pytest.org, pytest-with-eric.com)

**Test Architecture:**
```
tests/
‚îú‚îÄ‚îÄ unit/                           # Fast, isolated tests
‚îÇ   ‚îú‚îÄ‚îÄ test_variance.py           # Decimal precision, edge cases
‚îÇ   ‚îú‚îÄ‚îÄ test_consolidation.py
‚îÇ   ‚îî‚îÄ‚îÄ test_favorability.py
‚îÇ
‚îú‚îÄ‚îÄ integration/                    # API integrations
‚îÇ   ‚îú‚îÄ‚îÄ test_adaptive_client.py    # Requires credentials, use @pytest.mark.integration
‚îÇ   ‚îú‚îÄ‚îÄ test_databricks_client.py
‚îÇ   ‚îî‚îÄ‚îÄ test_gsheets_writer.py
‚îÇ
‚îú‚îÄ‚îÄ e2e/                           # End-to-end workflows
‚îÇ   ‚îú‚îÄ‚îÄ test_variance_workflow.py  # Full variance analysis
‚îÇ   ‚îî‚îÄ‚îÄ test_post_close_workflow.py
‚îÇ
‚îú‚îÄ‚îÄ fixtures/                       # Shared test data
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                # pytest fixtures
‚îÇ   ‚îú‚îÄ‚îÄ sample_data.py             # 50-account sample data
‚îÇ   ‚îî‚îÄ‚îÄ mock_api_responses.py      # Mock Adaptive/Databricks responses
‚îÇ
‚îî‚îÄ‚îÄ pytest.ini                      # pytest configuration
```

**pytest.ini Configuration:**
```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    integration: Integration tests requiring external services
    e2e: End-to-end workflow tests
    slow: Slow tests (>1 second)
    unit: Fast unit tests (default)
addopts =
    -v
    --strict-markers
    --cov=scripts
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=95
    --tb=short
```

**Test Fixtures Pattern (from FinancePy):**
```python
# tests/fixtures/conftest.py
import pytest
from decimal import Decimal
from pathlib import Path

@pytest.fixture
def sample_budget_data():
    """Realistic 50-account budget data."""
    return {
        "4000": {"name": "Subscription Revenue", "amount": Decimal("2500000.00")},
        "4010": {"name": "Premium Features", "amount": Decimal("450000.00")},
        # ... 48 more accounts (see data/samples/README.md)
    }

@pytest.fixture
def sample_actuals_with_variances():
    """Actuals with material variances for testing."""
    return {
        "4000": {"amount": Decimal("2875000.00")},  # +15% FAVORABLE
        "7030": {"amount": Decimal("420000.00")},   # +40% UNFAVORABLE
        # ... includes edge cases (zero budget, negatives, NULL)
    }

@pytest.fixture
def temp_excel_file(tmp_path):
    """Create temporary Excel file for testing."""
    file_path = tmp_path / "test_variance.xlsx"
    # Create Excel file with sample data
    return file_path
```

**Decimal Precision Testing (from PreciseMoney):**
```python
# tests/unit/test_decimal_precision.py
import pytest
from decimal import Decimal

def test_variance_uses_decimal_not_float():
    """Ensure Decimal type enforcement."""
    actual = Decimal('115000.00')
    budget = Decimal('100000.00')

    result = calculate_variance(actual, budget, 'revenue')

    assert isinstance(result.variance, Decimal)
    assert isinstance(result.percentage, Decimal)

def test_float_rejection():
    """Float types must be rejected."""
    with pytest.raises(TypeError, match="must be Decimal"):
        calculate_variance(115000.00, Decimal('100000.00'), 'revenue')
```

**Test Invocation Commands:**
```bash
# Run all tests with coverage (enforced by pre-commit)
pytest --cov=scripts --cov-fail-under=95

# Run only unit tests (fast feedback)
pytest tests/unit/ -v

# Run excluding integration tests (local development)
pytest -m "not integration"

# Run integration tests only (requires credentials)
pytest -m integration

# Run E2E tests (full workflows)
pytest -m e2e

# Generate HTML coverage report
pytest --cov=scripts --cov-report=html
open htmlcov/index.html
```

---

## Deployment Approach

### Environment Setup

**Development:**
```bash
# 1. Python environment
pyenv install 3.11.7
pyenv local 3.11.7
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# 2. Dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# 3. Configuration
cp config/.env.example config/.env
# Edit .env with appropriate values

# 4. Verify setup
python .claude/skills/financial-validator/scripts/validate_precision.py
pytest tests/ -v
```

**Production:**
[TO BE DETERMINED - depends on deployment target]
- Option 1: Local installation per user
- Option 2: Shared server deployment
- Option 3: Cloud function (serverless)

### Configuration Management

**config/fpa_config.yaml:**
```yaml
# Business rules and thresholds
variance_thresholds:
  percentage: 0.10  # 10%
  absolute: 50000   # $50,000

favorability_rules:
  revenue: "actual_gt_budget"
  expense: "actual_lt_budget"
  asset: "actual_gt_budget"
  liability: "actual_lt_budget"

output_settings:
  excel_formats:
    currency: "$#,##0.00"
    percentage: "0.00%"
  conditional_formatting:
    favorable_material: "#00FF00"    # Green
    unfavorable_material: "#FF0000"  # Red
    favorable_immaterial: "#FFFF00"  # Yellow
    unfavorable_immaterial: "#808080" # Gray
```

---

## Performance Considerations

### Data Volume Handling

**Small Datasets (<1,000 rows):**
- Load entire file into memory
- Process in single pass
- Expected time: <10 seconds

**Medium Datasets (1,000-10,000 rows):**
- Load into memory with chunking if needed
- Process in batches of 5,000
- Expected time: <60 seconds

**Large Datasets (>10,000 rows):**
- Use chunked reading: `pd.read_excel(chunksize=5000)`
- Process incrementally
- Write results progressively
- Expected time: [TO BE MEASURED based on testing]

### Optimization Strategy

**Rule:** No premature optimization

**Approach:**
1. Implement with clarity and correctness first
2. Profile with realistic data
3. Optimize bottlenecks only
4. Measure improvements
5. Document performance characteristics

**Profiling:**
```python
import cProfile
import pstats

def profile_variance_analysis():
    """Profile variance analysis performance."""
    profiler = cProfile.Profile()
    profiler.enable()

    # Run analysis
    analyzer.analyze(budget_file, actuals_file, output_file)

    profiler.disable()
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(20)  # Top 20 functions
```

---

## Security & Compliance

### Data Protection

**Sensitive Data (NEVER commit):**
- `.env` files with credentials
- `credentials.json` (Google service account)
- Actual financial data in `/data/input/`
- Generated reports in `/data/output/`
- Log files with PII

**Gitignore Rules:**
```
# Credentials
.env
credentials.json
*.pem
*.key

# Data
data/input/
data/output/
logs/

# Environment
venv/
__pycache__/
*.pyc
```

### Audit Trail Requirements

**Every transformation must log:**
```python
audit_entry = {
    'timestamp': datetime.now(UTC).isoformat(),
    'user': os.getenv('USER', 'unknown'),
    'operation': 'variance_calculation',
    'source_files': [str(budget_file), str(actuals_file)],
    'output_file': str(output_file),
    'records_processed': len(df),
    'thresholds': {
        'percentage': config['percentage_threshold'],
        'absolute': config['absolute_threshold']
    },
    'material_variances_count': material_count,
    'errors': error_list
}

logger.info("Audit trail", extra=audit_entry)
```

### Access Control

**File Permissions:**
- Configuration files: Read-only after setup
- Credentials: Restricted to application user
- Output files: User-specific access

**API Authentication:**
- Google Workspace: Service account with minimal scopes
- Read-only access where possible
- Scope limitation per function

---

## Development Workflow

### Git Branch Strategy

**Branches:**
- `main` - Production-ready code
- `develop` - Integration branch
- `feature/epic-1-story-1` - Feature branches
- `bugfix/issue-123` - Bug fixes
- `claude/session-id` - Claude Code branches

**Workflow:**
1. Create feature branch from `develop`
2. Implement with tests
3. Run quality gates (hooks)
4. Create PR to `develop`
5. Code review (@code-reviewer agent)
6. Merge after approval
7. Periodic merge `develop` ‚Üí `main`

### Commit Message Format

```
type(scope): short description

Longer description if needed.

- Bullet points for details
- Reference issues: Closes #123
- Reference specs: Implements spec.md Story 1.1
```

**Types:** feat, fix, docs, test, refactor, chore

### Quality Gates (Automated)

**Pre-commit (Local):**
- Black formatting
- Ruff linting
- MyPy type checking
- Basic test suite

**Stop Hook (Claude Code):**
- Float usage check (BLOCKING)
- Type hints check (WARNING)
- Financial validator tests
- Python syntax validation

**CI/CD (Future):**
- Full test suite
- Coverage report
- Security scanning
- Performance benchmarks

---

## Next Steps & Priorities

### Phase 1: Foundation (Current)
- [x] Architecture design
- [x] CLAUDE.md behavioral configuration
- [x] Financial validator skill
- [x] Quality gates (hooks)
- [ ] Core directory structure
- [ ] Base classes and utilities

### Phase 2: Epic 1 Implementation
- [ ] Story 1.1: Multi-department consolidation
- [ ] Story 1.2: GL account reconciliation
- [ ] Unit tests for Epic 1
- [ ] Integration tests
- [ ] Documentation

### Phase 3: Epic 2 Implementation
- [ ] Story 2.1: Variance calculation
- [ ] Story 2.2: Favorability assessment
- [ ] Story 2.3: Materiality flagging
- [ ] Comprehensive edge case testing
- [ ] Independent verification

### Phase 4: Epic 3 Implementation
- [ ] Story 3.1: Excel report generation
- [ ] Story 3.2: Google Slides integration
- [ ] Template system
- [ ] Chart generation

### Phase 5: Production Readiness
- [ ] Performance optimization
- [ ] Security audit
- [ ] User documentation
- [ ] Deployment packaging
- [ ] Training materials

---

## Architecture Restructure (Added 2025-11-08)

### Decision: Claude Code-Native Approach

**Change:** Shifted from traditional Python package distribution (`packages/fpa-core`, etc.) to Claude Code-native architecture (`.claude/` skills, commands, agents).

**Rationale:**
- Target users are FP&A professionals, not developers
- Conversational interface with human-in-loop matches FP&A approval workflows
- No installation burden for end users
- Iterative refinement via markdown editing (non-technical)

### Directory Structure (Final)

```
cc-sf-assistant/
‚îú‚îÄ‚îÄ .claude/
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev/                      # Development agents
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ script-generator.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ script-validator.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test-generator.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ code-reviewer.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prod/                     # Production agents
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finance-reviewer.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data-validator.md
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reconciler.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shared/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ research-agent.md
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev/                      # Development workflows
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ create-script.md      # /create-script
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validate-script.md    # /validate-script
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ review-code.md        # /review-code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prod/                     # Production workflows
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monthly-close.md      # /monthly-close
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variance-analysis.md  # /variance-analysis
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consolidate.md        # /consolidate
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ board-deck.md         # /board-deck
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shared/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ help.md
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ config.md
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ skills/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dev/                      # Dev skills (auto-invoked during dev)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ python-best-practices/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ financial-script-generator/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test-suite-generator/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prod/                     # Prod skills (auto-invoked during prod)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variance-analyzer/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ account-mapper/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report-generator/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ shared/                   # Shared skills (always auto-invoked)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ decimal-precision-enforcer/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ audit-trail-enforcer/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ templates/                    # Templates for creating skills/commands/agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ skills/SKILL_TEMPLATE.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands/COMMAND_TEMPLATE.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/AGENT_TEMPLATE.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ TDD_WORKFLOW.md
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ RESEARCH_PLAN_IMPLEMENT_VERIFY.md
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ hooks/
‚îÇ       ‚îî‚îÄ‚îÄ stop.sh                   # Quality gate (runs after every response)
‚îÇ
‚îú‚îÄ‚îÄ scripts/                          # Pre-written validated calculation scripts
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variance.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ consolidation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ favorability.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ materiality.py
‚îÇ   ‚îú‚îÄ‚îÄ integrations/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gsheet_reader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gsheet_writer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excel_reader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ excel_writer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gslides_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monthly_close.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variance_report.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ board_deck.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îú‚îÄ‚îÄ validator.py
‚îÇ       ‚îî‚îÄ‚îÄ config_loader.py
‚îÇ
‚îú‚îÄ‚îÄ external/                         # Cloned GitHub repos (git submodules)
‚îÇ   ‚îú‚îÄ‚îÄ humanlayer/
‚îÇ   ‚îú‚îÄ‚îÄ mcp-gdrive/
‚îÇ   ‚îú‚îÄ‚îÄ gspread/
‚îÇ   ‚îú‚îÄ‚îÄ slidio/
‚îÇ   ‚îú‚îÄ‚îÄ pyfpa/
‚îÇ   ‚îî‚îÄ‚îÄ py-money/
‚îÇ
‚îú‚îÄ‚îÄ templates/                        # Report templates
‚îÇ   ‚îú‚îÄ‚îÄ variance_report.xlsx
‚îÇ   ‚îú‚îÄ‚îÄ board_deck.pptx
‚îÇ   ‚îî‚îÄ‚îÄ consolidated_report.xlsx
‚îÇ
‚îú‚îÄ‚îÄ tests/                            # Comprehensive test suite
‚îÇ   ‚îú‚îÄ‚îÄ test_variance.py
‚îÇ   ‚îú‚îÄ‚îÄ test_consolidation.py
‚îÇ   ‚îú‚îÄ‚îÄ test_integrations.py
‚îÇ   ‚îî‚îÄ‚îÄ test_edge_cases.py
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.yaml
‚îÇ   ‚îî‚îÄ‚îÄ credentials/                  # OAuth + service account keys
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ COMPREHENSIVE_GITHUB_SOURCES.md
‚îÇ   ‚îú‚îÄ‚îÄ user-guides/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ
‚îú‚îÄ‚îÄ spec.md
‚îú‚îÄ‚îÄ plan.md
‚îú‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ EXTERNAL_DEPENDENCIES.md
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ .gitignore
```

### Workflow Separation: Dev vs Prod

#### **Dev Workflows** (Script Generation)
**Purpose:** Generate new financial calculation scripts when needed.

**Trigger:** User requests analysis not covered by existing scripts.
**Example:** `/create-script "Calculate YoY revenue growth by department"`

**Process:**
1. Research existing patterns (no coding)
2. Generate formal specification
3. Get human approval on spec
4. Follow TDD workflow:
   - RED: Write failing tests
   - GREEN: Implement with Decimal
   - REFACTOR: Add docstrings, error handling, logging
   - VALIDATE: Independent agent review
5. Human approval on final script
6. Save to `scripts/` directory
7. Script now available for prod workflows

**Skills Auto-Invoked:**
- `python-best-practices` - Enforces Decimal, type hints, error handling
- `financial-script-generator` - Uses variance/consolidation patterns
- `test-suite-generator` - Generates edge case tests
- `decimal-precision-enforcer` - Blocks float usage
- `audit-trail-enforcer` - Ensures logging

**Agents Used:**
- `script-generator` - Writes Python code from spec
- `test-generator` - Creates comprehensive tests
- `script-validator` - Runs pytest, mypy, ruff, bandit, coverage
- `code-reviewer` - Independent review (separate context, read-only)

#### **Prod Workflows** (Script Execution)
**Purpose:** Execute pre-written, validated scripts for daily FP&A tasks.

**Trigger:** User requests common FP&A analysis.
**Example:** `/variance-analysis budget.xlsx actuals.xlsx`

**Process:**
1. Execute pre-written script from `scripts/`
2. Human reviews results (e.g., flagged variances)
3. Human approves report
4. Export to Excel or Google Sheets
5. Audit trail logged

**Skills Auto-Invoked:**
- `variance-analyzer` - Validates variance calculations
- `account-mapper` - Handles unmapped accounts
- `report-generator` - Formats output
- `decimal-precision-enforcer` - Validates precision
- `audit-trail-enforcer` - Logs transformations

**Agents Used:**
- `finance-reviewer` - Reviews financial outputs for accuracy
- `data-validator` - Validates input data quality
- `reconciler` - Reconciles unmapped accounts with human input

### Data Integration Approach

#### Phase 1: Excel-First (MVP)
- Focus on local Excel file processing
- Libraries: openpyxl (read), xlsxwriter (write with formatting)
- No cloud dependencies
- Works offline
- Faster development

#### Phase 2: Google Integration
- Google Sheets: gspread + gspread-dataframe
- Google Slides: slidio patterns (or custom implementation)
- Authentication: OAuth + Service Account JSON
- Credentials: `config/credentials/`
- Skills to convert Excel ‚Üí Google workflows

### Script Generation Validation Requirements

**Problem:** LLMs cannot be trusted to perform financial math directly (hallucination risk).
**Solution:** Generate robust, tested Python scripts that perform deterministic calculations.

**Validation Pipeline (Enforced):**
1. Specification generated and human-approved
2. TDD cycle: Write tests ‚Üí Implement ‚Üí Refactor
3. Automated validation:
   - pytest (test execution)
   - mypy (type checking)
   - ruff (linting)
   - bandit (security)
   - coverage (>95% required - ENFORCED by pre-commit hook)
4. Independent code review by separate agent (read-only context)
5. Human final approval
6. Script saved to `scripts/` directory

**Anti-Patterns Blocked:**
- ‚ùå Float for currency ‚Üí `decimal-precision-enforcer` blocks
- ‚ùå Missing type hints ‚Üí `python-best-practices` requires
- ‚ùå No error handling ‚Üí `python-best-practices` requires
- ‚ùå No audit logging ‚Üí `audit-trail-enforcer` requires
- ‚ùå Low test coverage ‚Üí `script-validator` blocks (<95%)

### External Library Integration Strategy

**Installed via pip:**
- pandas (data manipulation)
- gspread + gspread-dataframe (Google Sheets)
- openpyxl (Excel read)
- xlsxwriter (Excel write with formatting)
- google-auth (authentication)

**Cloned for Reference/Adaptation:**
- humanlayer - Study human-in-loop patterns
- pyfpa - Study FP&A consolidation algorithms (may install if adaptable)
- slidio - Study Google Slides patterns (may install or adapt)
- py-money - Reference Decimal precision (use Python's built-in decimal)
- mcp-gdrive - Study MCP protocol patterns

**Why Keep Cloned Repos:**
- Security audit before use
- Learn implementation patterns
- Pin exact versions (git submodules)
- Offline development
- Customize if needed

### Workflow Templates (`.claude/templates/`)

**Research Findings (10 Sources):**
- GitHub: anthropics/skills (official templates)
- GitHub: alirezarezvani/claude-code-skill-factory (skill factory)
- GitHub: travisvn/awesome-claude-skills (community examples)
- GitHub: Pimzino/claude-code-spec-workflow (RPIV workflow)
- GitHub: nizos/tdd-guard (TDD enforcement)
- Anthropic: Official skills best practices
- Anthropic: Claude Code best practices
- Anthropic: Subagents documentation
- Claude Code TDD guides (multiple sources)
- Community slash command examples

**Created Templates:**
1. **SKILL_TEMPLATE.md** - YAML frontmatter, Progressive Disclosure pattern
2. **COMMAND_TEMPLATE.md** - $ARGUMENTS placeholder, human checkpoints
3. **AGENT_TEMPLATE.md** - Tool permissions, role definition
4. **TDD_WORKFLOW.md** - RED-GREEN-REFACTOR-VALIDATE cycle
5. **RESEARCH_PLAN_IMPLEMENT_VERIFY.md** - Structured feature development

### Implementation Priority

**Phase 1: Infrastructure (Week 1-2)**
- Create `.claude/` directory structure (dev/prod/shared)
- Create templates for skills/commands/agents
- Set up `scripts/` directory
- Configure `pyproject.toml` dependencies
- Set up `tests/` directory with pytest

**Phase 2: Dev Workflows (Week 3-4)**
- Build dev skills (python-best-practices, financial-script-generator, test-suite-generator)
- Build dev agents (script-generator, script-validator, test-generator, code-reviewer)
- Build dev commands (/create-script, /validate-script, /review-code)
- Test script generation pipeline

**Phase 3: Core Scripts - Excel (Week 5-7)**
- Pre-write core calculation scripts (variance, consolidation, favorability, materiality)
- Excel integration scripts (reader, writer)
- Comprehensive tests for all scripts
- Validate with independent code review

**Phase 4: Prod Workflows - Excel (Week 8-10)**
- Build prod skills (variance-analyzer, account-mapper, report-generator)
- Build prod agents (finance-reviewer, data-validator, reconciler)
- Build prod commands (/monthly-close, /variance-analysis, /consolidate)
- End-to-end testing with sample data

**Phase 5: Google Integration (Week 11-13)**
- Google Sheets integration (gspread)
- Google Slides integration (slidio patterns or custom)
- OAuth + Service Account authentication
- Excel ‚Üí Google conversion skills
- Integration testing

**Phase 6: Polish & Documentation (Week 14-15)**
- User documentation (non-technical guides)
- Workflow documentation
- Training materials
- Performance optimization
- Security audit
- Life360 branding customization (logo, colors, templates)

---

## Implementation Details for Operational Decisions

### 1. Script Versioning (Git-Based)

**Rule:** NEVER create files named `script_v2.py`, `script_v3.py`, `script-new.py`, etc.

**Implementation:**
```bash
# When updating existing script
git add scripts/core/variance.py
git commit -m "feat: add QoQ variance calculation to variance.py"
git push

# To revert to old version
git log scripts/core/variance.py  # Find commit hash
git checkout <commit-hash> scripts/core/variance.py
```

**Enforced By:**
- `.claude/hooks/stop.sh` checks for files matching `*_v[0-9]*.py`, `*-new.py`, `*-old.py` patterns
- Blocks commit if versioned filenames detected

**Benefits:**
- Proper version control with diffs
- Rollback to any previous state
- Clear commit history
- No file naming confusion

---

### 2. Centralized Audit Log

**Structure:**
```
config/
‚îú‚îÄ‚îÄ audit.log              # Actual audit entries (git ignored)
‚îú‚îÄ‚îÄ .gitignore             # Ignores audit.log data file
‚îî‚îÄ‚îÄ audit-schema.json      # Log structure (version controlled)
```

**Audit Entry Format (JSON):**
```json
{
  "timestamp": "2025-11-08T14:32:15.123Z",
  "user": "user@life360.com",
  "script": "scripts/workflows/variance_report.py",
  "operation": "variance_calculation",
  "inputs": {
    "budget_file": "budget_2025.xlsx",
    "actual_file": "actuals_nov.xlsx"
  },
  "outputs": {
    "variance_report": "variance_nov_2025.xlsx",
    "material_variances_count": 3
  },
  "metadata": {
    "execution_time_ms": 2341,
    "rows_processed": 50,
    "errors": []
  }
}
```

**Implementation in Scripts:**
```python
# scripts/utils/logger.py
from loguru import logger
import json
from pathlib import Path
from datetime import datetime

AUDIT_LOG = Path("config/audit.log")

def log_audit_entry(
    script: str,
    operation: str,
    inputs: dict,
    outputs: dict,
    metadata: dict
) -> None:
    """Write structured audit entry to centralized log."""
    entry = {
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "user": os.getenv("USER", "unknown"),
        "script": script,
        "operation": operation,
        "inputs": inputs,
        "outputs": outputs,
        "metadata": metadata
    }

    with AUDIT_LOG.open("a") as f:
        f.write(json.dumps(entry) + "\n")
```

**Querying Audit Log:**
```python
# Example: Find all variance calculations in November
import json
from pathlib import Path

with Path("config/audit.log").open() as f:
    for line in f:
        entry = json.loads(line)
        if entry["operation"] == "variance_calculation":
            if "2025-11" in entry["timestamp"]:
                print(entry)
```

**Skills/Agents Enforcing:**
- `audit-trail-enforcer` skill checks all scripts import and use `log_audit_entry()`
- `code-reviewer` agent verifies audit logging before approval

---

### 3. Data Validation Pre-Checks

**Workflow Integration:**

Every prod workflow starts with validation phase:

```markdown
## /variance-analysis Workflow

### Phase 1: Data Validation (Automatic)
1. Invoke `data-validator` agent
2. Check budget file:
   - Required columns exist (Account, Department, Amount)
   - Data types correct (Amount is numeric)
   - No NULL values in required fields
   - Amounts are positive decimals
3. Check actual file (same checks)
4. Generate validation report
5. **HUMAN CHECKPOINT:** User reviews validation report and approves/rejects

### Phase 2: Execution (After Approval)
1. Execute variance calculation script
2. Generate report
3. **HUMAN CHECKPOINT:** User reviews variance results
4. Export to Excel/Sheets
5. Log audit entry
```

**Validation Report Format:**
```
üìä Data Validation Report

Budget File: budget_2025.xlsx
‚úÖ File exists and is readable
‚úÖ Required columns present: Account, Department, Amount
‚úÖ Data types valid: Amount is numeric (50/50 rows)
‚úÖ No NULL values in required fields
‚úÖ All amounts are positive Decimals
‚úÖ 50 accounts found

Actual File: actuals_nov.xlsx
‚úÖ File exists and is readable
‚úÖ Required columns present: Account, Department, Amount
‚ö†Ô∏è  WARNING: 2 NULL values found in Amount column (rows 23, 47)
‚úÖ Data types valid: Amount is numeric (48/50 rows)
‚ùå ERROR: 2 amounts are negative (rows 15, 32)
‚úÖ 50 accounts found

‚ùå VALIDATION FAILED - 1 error, 1 warning

Proceed anyway? (y/n):
```

**Implementation:**
```python
# scripts/utils/validator.py
from decimal import Decimal
import pandas as pd
from typing import NamedTuple

class ValidationResult(NamedTuple):
    passed: bool
    errors: list[str]
    warnings: list[str]
    summary: str

def validate_financial_file(
    file_path: str,
    required_columns: list[str],
    amount_column: str = "Amount"
) -> ValidationResult:
    """Validate Excel file before processing."""
    errors = []
    warnings = []

    # Check file exists
    if not Path(file_path).exists():
        errors.append(f"File not found: {file_path}")
        return ValidationResult(False, errors, warnings, "")

    # Load file
    df = pd.read_excel(file_path)

    # Check required columns
    missing = [col for col in required_columns if col not in df.columns]
    if missing:
        errors.append(f"Missing columns: {missing}")

    # Check for NULLs
    null_counts = df[required_columns].isnull().sum()
    for col, count in null_counts.items():
        if count > 0:
            warnings.append(f"{count} NULL values in {col}")

    # Check amount is Decimal-compatible
    try:
        df[amount_column] = df[amount_column].apply(Decimal)
    except:
        errors.append(f"{amount_column} contains non-numeric values")

    # Check for negative amounts (may be valid in some contexts)
    negatives = (df[amount_column] < 0).sum()
    if negatives > 0:
        errors.append(f"{negatives} negative amounts found")

    passed = len(errors) == 0
    summary = f"{'‚úÖ PASSED' if passed else '‚ùå FAILED'} - {len(errors)} errors, {len(warnings)} warnings"

    return ValidationResult(passed, errors, warnings, summary)
```

**Skills/Agents:**
- `data-validator` agent (prod) - Runs validation, generates report, waits for human approval
- `decimal-precision-enforcer` skill (shared) - Ensures amounts are Decimal-compatible

---

### 4. Template Customization

**Phase 1-5: Generic Templates**

```
templates/
‚îú‚îÄ‚îÄ variance_report.xlsx         # Generic variance report
‚îú‚îÄ‚îÄ board_deck.pptx              # Generic board presentation
‚îî‚îÄ‚îÄ consolidated_report.xlsx     # Generic consolidation output
```

**Phase 6: Life360 Branding**

User provides:
- Life360 logo (PNG, SVG)
- Brand colors (hex codes)
- Font specifications
- PowerPoint master template

**Implementation:**
```python
# scripts/utils/branding.py
BRAND_CONFIG = {
    "company_name": "Life360",
    "logo_path": "templates/assets/life360_logo.png",
    "primary_color": "#5200FF",  # Life360 purple
    "secondary_color": "#00D4AA",  # Life360 teal
    "font_family": "Montserrat",
}

def apply_branding_to_pptx(prs: Presentation) -> Presentation:
    """Apply Life360 branding to PowerPoint presentation."""
    # Add logo to title slide
    # Set color scheme
    # Apply fonts
    return prs
```

**Created During Phase 6:**
```
templates/
‚îú‚îÄ‚îÄ life360/
‚îÇ   ‚îú‚îÄ‚îÄ variance_report.xlsx     # Branded variance report
‚îÇ   ‚îú‚îÄ‚îÄ board_deck.pptx          # Branded board deck
‚îÇ   ‚îú‚îÄ‚îÄ consolidated_report.xlsx # Branded consolidation
‚îÇ   ‚îî‚îÄ‚îÄ assets/
‚îÇ       ‚îú‚îÄ‚îÄ life360_logo.png
‚îÇ       ‚îî‚îÄ‚îÄ brand_colors.json
‚îî‚îÄ‚îÄ generic/                      # Keep generic for reference
    ‚îú‚îÄ‚îÄ variance_report.xlsx
    ‚îî‚îÄ‚îÄ board_deck.pptx
```

---

### 5. Error Recovery & State Management

**Workflow State Structure:**

```
config/
‚îî‚îÄ‚îÄ workflow-state/
    ‚îú‚îÄ‚îÄ monthly-close-2025-11.json       # State for Nov 2025 monthly close
    ‚îú‚îÄ‚îÄ variance-analysis-2025-11.json   # State for Nov 2025 variance
    ‚îî‚îÄ‚îÄ .gitignore                        # Ignore state files
```

**State File Format:**
```json
{
  "workflow": "monthly-close",
  "period": "2025-11",
  "started_at": "2025-11-08T10:00:00Z",
  "last_updated": "2025-11-08T14:32:15Z",
  "status": "in_progress",
  "completed_steps": [
    "validate_input_data",
    "consolidate_departments",
    "calculate_variances"
  ],
  "current_step": "generate_board_deck",
  "remaining_steps": [
    "export_to_google_sheets",
    "send_notifications"
  ],
  "intermediate_outputs": {
    "consolidated_file": "/tmp/consolidated_nov2025.xlsx",
    "variance_file": "/tmp/variance_nov2025.xlsx"
  },
  "error": null
}
```

**Resumption Workflow:**

```python
# scripts/workflows/monthly_close.py
from pathlib import Path
import json

STATE_DIR = Path("config/workflow-state")

def save_state(workflow: str, period: str, state: dict) -> None:
    """Save workflow state for resumption."""
    state_file = STATE_DIR / f"{workflow}-{period}.json"
    state_file.write_text(json.dumps(state, indent=2))

def load_state(workflow: str, period: str) -> dict | None:
    """Load workflow state if exists."""
    state_file = STATE_DIR / f"{workflow}-{period}.json"
    if state_file.exists():
        return json.loads(state_file.read_text())
    return None

def monthly_close_workflow(period: str, resume: bool = False):
    """Run monthly close workflow with error recovery."""
    state = load_state("monthly-close", period) if resume else None

    if state:
        print(f"Resuming from step: {state['current_step']}")
        steps = state['remaining_steps']
    else:
        print("Starting new monthly close workflow")
        steps = ["validate", "consolidate", "variance", "board_deck", "export"]

    for step in steps:
        try:
            print(f"Executing step: {step}")
            execute_step(step)

            # Update state after each step
            save_state("monthly-close", period, {
                "current_step": step,
                "completed_steps": [...],
                "status": "in_progress"
            })
        except Exception as e:
            # Save error state
            save_state("monthly-close", period, {
                "current_step": step,
                "status": "failed",
                "error": str(e)
            })
            print(f"‚ùå Workflow failed at step {step}. State saved. Resume with: /monthly-close --resume")
            raise

    # Mark complete
    save_state("monthly-close", period, {"status": "completed"})
```

**Command with Resume:**
```markdown
---
name: monthly-close
description: Monthly close workflow with error recovery
---

# Monthly Close Workflow

## Usage
`/monthly-close november [--resume]`

## Arguments
- Period: Month name or YYYY-MM format
- --resume: Resume from last saved state (optional)

## Workflow
1. Check for existing state file
2. If --resume flag: Load state and continue from last step
3. If new: Start from beginning
4. Save state after each step
5. On error: Save error state, inform user how to resume
```

**Benefits:**
- Long workflows don't lose progress on transient failures
- User can review intermediate outputs before continuing
- Network/file issues are recoverable
- Better user experience for multi-hour workflows

---

### 6. Testing & Quality Assurance

**Sample Data Structure:**

```
data/
‚îú‚îÄ‚îÄ samples/                      # Realistic sample data (version controlled)
‚îÇ   ‚îú‚îÄ‚îÄ budget_2025.xlsx         # Sample budget with 50 accounts
‚îÇ   ‚îú‚îÄ‚îÄ actuals_nov_2025.xlsx    # Sample actuals for November
‚îÇ   ‚îú‚îÄ‚îÄ actuals_dec_2025.xlsx    # Sample actuals for December
‚îÇ   ‚îú‚îÄ‚îÄ departments/             # Multi-department data for consolidation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finance_budget.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marketing_budget.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ operations_budget.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finance_actuals.xlsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ marketing_actuals.xlsx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ operations_actuals.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ README.md                # Documentation of sample data structure
‚îî‚îÄ‚îÄ .gitkeep
```

**Sample Data Characteristics:**
- Realistic account names (Revenue, COGS, Salaries, Marketing, etc.)
- Mix of revenue and expense accounts
- Realistic dollar amounts ($10k-$500k range)
- Intentional edge cases:
  - 1-2 accounts with zero budget (division by zero test)
  - 1-2 negative actuals (error handling test)
  - 1-2 NULL values (validation test)
  - Material variances (>10% and >$50k)
  - Immaterial variances (<10% or <$50k)

**Pre-Commit Hook Implementation (Modernized - November 2025):**

**Research Source:** Ruff (astral-sh/ruff-pre-commit) - Replaces Black, Flake8, isort, bandit, and more. 200x faster than traditional tools.

```bash
# .git/hooks/pre-commit (created automatically)
#!/bin/bash

echo "Running pre-commit quality checks..."

# Run pytest with 95% coverage requirement
echo "‚úì Running tests..."
poetry run pytest --cov=scripts --cov-fail-under=95 || { echo "‚ùå Tests failed or coverage <95%"; exit 1; }

# Run mypy (type checking - Ruff doesn't do this yet)
echo "‚úì Running type checks..."
poetry run mypy scripts/ || { echo "‚ùå Type check failed"; exit 1; }

# Run Ruff - linting + formatting + security checks
echo "‚úì Running Ruff (linting, formatting, security)..."
poetry run ruff check scripts/ || { echo "‚ùå Ruff check failed"; exit 1; }
poetry run ruff format --check scripts/ || { echo "‚ùå Ruff format failed"; exit 1; }

# Check for versioned filenames
echo "‚úì Checking for versioned filenames..."
if git diff --cached --name-only | grep -E "_v[0-9]+\.py|_new\.py|_old\.py"; then
    echo "‚ùå Versioned filenames detected (use git for versioning)"
    exit 1
fi

echo "‚úÖ All quality checks passed"
exit 0
```

**Tools Replaced:**
- ‚ùå **bandit** ‚Üí ‚úÖ **Ruff** (includes security checks via `ruff check`)
- ‚ùå **black** ‚Üí ‚úÖ **Ruff** (includes formatting via `ruff format`)
- ‚ùå **isort** ‚Üí ‚úÖ **Ruff** (includes import sorting)
- ‚ùå **flake8** ‚Üí ‚úÖ **Ruff** (includes linting)
- ‚úÖ **mypy** (kept - Ruff doesn't do type checking yet)
- ‚úÖ **pytest** (kept - testing framework)

**Installation:**
```bash
# scripts/utils/install_hooks.py
from pathlib import Path
import shutil

def install_pre_commit_hook():
    """Install pre-commit hook for quality gates."""
    hook_source = Path(".claude/hooks/pre-commit")
    hook_dest = Path(".git/hooks/pre-commit")

    if hook_source.exists():
        shutil.copy(hook_source, hook_dest)
        hook_dest.chmod(0o755)
        print("‚úÖ Pre-commit hook installed")
    else:
        print("‚ö†Ô∏è  Hook source not found")
```

**Skills/Commands:**
- `/setup` command runs `install_pre_commit_hook()` during initial setup
- `python-best-practices` skill references sample data for test generation

---

### 7. Deployment & Setup (Single-User, Local)

**Setup Process:**

```bash
# 1. Clone repository
git clone <repository-url>
cd cc-sf-assistant

# 2. Initialize submodules (external dependencies)
git submodule update --init --recursive

# 3. Create virtual environment with Poetry
poetry install

# 4. Install pre-commit hooks
poetry run python scripts/utils/install_hooks.py

# 5. Configure credentials (manual)
mkdir -p config/credentials
# User adds service-account.json, oauth-token.json manually

# 6. Verify setup
poetry run pytest
```

**No Docker, No Cloud:**
- Simple Python virtual environment managed by Poetry
- All processing happens locally
- No shared infrastructure, no authentication layer
- Each user has independent setup

**Distribution Model:**
- Users download/clone repository
- Follow QUICK_START.md instructions
- Configure credentials for their Google account
- Customize for their company (Life360 for this user)

---

### 8. Security (Simple Approach)

**Credential Management:**

```
config/
‚îú‚îÄ‚îÄ credentials/
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore              # Ignore all credentials
‚îÇ   ‚îú‚îÄ‚îÄ service-account.json    # Google service account (user adds)
‚îÇ   ‚îú‚îÄ‚îÄ oauth-token.json        # OAuth token (user adds)
‚îÇ   ‚îî‚îÄ‚îÄ README.md               # Instructions for obtaining credentials
‚îî‚îÄ‚îÄ settings.yaml               # Non-sensitive settings (version controlled)
```

**.gitignore:**
```
# Credentials (never commit)
config/credentials/*.json
config/credentials/*.token

# Audit logs (contain sensitive data)
config/audit.log

# Workflow state (may contain sensitive paths)
config/workflow-state/*.json

# Test outputs
/tmp/
*.xlsx
*.pptx
```

**Security Principles:**
- User responsible for securing their local machine
- No encryption at rest (keeps setup simple)
- Credentials never committed to git
- Clear documentation on credential setup

**Future Consideration:**
- Add encryption at rest in Phase 7+ if needed
- Use system keychain (macOS Keychain, Windows Credential Manager)
- For now: simple file-based storage with .gitignore

---

### 9. Documentation & Training (Jupyter Notebooks)

**Notebook Structure:**

```
docs/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_getting_started.ipynb        # Setup, verify installation
‚îÇ   ‚îú‚îÄ‚îÄ 02_variance_analysis.ipynb     # Monthly variance workflow
‚îÇ   ‚îú‚îÄ‚îÄ 03_monthly_close.ipynb         # Full monthly close process
‚îÇ   ‚îú‚îÄ‚îÄ 04_board_deck.ipynb            # Generate board presentation
‚îÇ   ‚îú‚îÄ‚îÄ 05_consolidation.ipynb         # Multi-department consolidation
‚îÇ   ‚îú‚îÄ‚îÄ 06_custom_analysis.ipynb       # Creating custom scripts via dev workflow
‚îÇ   ‚îú‚îÄ‚îÄ 07_google_integration.ipynb    # Google Sheets/Slides integration
‚îÇ   ‚îî‚îÄ‚îÄ data/                           # Notebook-specific sample data
‚îÇ       ‚îú‚îÄ‚îÄ sample_budget.xlsx
‚îÇ       ‚îî‚îÄ‚îÄ sample_actuals.xlsx
‚îî‚îÄ‚îÄ user-guides/                        # Markdown guides (non-executable)
    ‚îú‚îÄ‚îÄ troubleshooting.md
    ‚îú‚îÄ‚îÄ faq.md
    ‚îî‚îÄ‚îÄ best-practices.md
```

**Notebook Features:**
- Executable cells with actual code
- Sample data embedded or referenced
- Expected outputs shown
- Users can modify and experiment
- Version-controlled (`.ipynb` files)

**Example Notebook (variance_analysis):**
```python
# Cell 1: Setup
import pandas as pd
from decimal import Decimal
from scripts.core.variance import calculate_variance

# Cell 2: Load sample data
budget = pd.read_excel("../data/samples/budget_2025.xlsx")
actuals = pd.read_excel("../data/samples/actuals_nov_2025.xlsx")

# Cell 3: Run variance analysis
variance_results = calculate_variance(budget, actuals, account_type="revenue")

# Cell 4: Display results
print(variance_results)

# Cell 5: Visualize material variances
import matplotlib.pyplot as plt
material = variance_results[variance_results['material'] == True]
material.plot(kind='bar', x='account', y='variance_pct')
plt.title("Material Variances (>10%)")
plt.show()
```

**Why Notebooks:**
- Executable documentation (users can run it)
- Interactive learning (modify and see results)
- Version-controlled (track changes)
- No video maintenance burden
- Users can copy code for their own analyses

**No Interactive CLI Help:**
- `/help` provides simple text help
- References notebooks for tutorials
- No step-by-step interactive walkthroughs in CLI

---

### 10. Monitoring & Notifications (Future)

**Current State (MVP):**
- No automated performance metrics tracking
- No error notifications (email, Slack, etc.)
- Errors displayed in Claude Code interface
- Errors logged to `config/audit.log`

**Future Additions (Post-MVP):**

**Performance Metrics (Phase 7+):**
```python
# Future: scripts/utils/metrics.py
from dataclasses import dataclass
from datetime import datetime

@dataclass
class PerformanceMetrics:
    script: str
    execution_time_ms: int
    memory_usage_mb: float
    rows_processed: int
    timestamp: datetime

def log_metrics(metrics: PerformanceMetrics) -> None:
    """Log performance metrics for analysis."""
    # Future implementation
    pass
```

**Error Notifications (Phase 7+):**
```python
# Future: scripts/utils/notifications.py
def send_error_notification(
    error: Exception,
    workflow: str,
    context: dict
) -> None:
    """Send error notification via email/Slack."""
    # Future implementation
    pass
```

**Why Not Now:**
- Keeps MVP simple
- Claude Code already informs user of errors
- Can add monitoring later if bottlenecks identified
- Focus on core functionality first

---

## Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0-DRAFT | 2025-11-08 | Claude | Initial technical planning document |

---

## References

- **spec.md** - Business requirements (WHAT to build)
- **CLAUDE.md** - Behavioral configuration (HOW Claude operates)
- **README.md** - Project overview and quick start
- **.claude/** - Claude Code configuration (Skills, Commands, Agents, Hooks)

---

**END OF TECHNICAL PLANNING DOCUMENT**

*This document defines HOW to build what spec.md describes. Implementation should follow this plan while adapting to discoveries made during development.*
